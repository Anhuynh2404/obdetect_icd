{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4333147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/an/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
      "Finish initialize NanoDet-Plus Head.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NanoDetPlus(\n",
       "  (backbone): ShuffleNetV2(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (stage2): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fpn): GhostPAN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (reduce_layers): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(116, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(232, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(464, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (top_down_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_in_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_out_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): NanoDetPlusHead(\n",
       "    (distribution_project): Integral()\n",
       "    (loss_qfl): QualityFocalLoss()\n",
       "    (loss_dfl): DistributionFocalLoss()\n",
       "    (loss_bbox): GIoULoss()\n",
       "    (cls_convs): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gfl_cls): ModuleList(\n",
       "      (0): Conv2d(96, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(96, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(96, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (aux_fpn): GhostPAN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (reduce_layers): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(116, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(232, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(464, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (top_down_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_in_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_out_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (dwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux_head): SimpleConvHead(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (cls_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (reg_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (gfl_cls): Conv2d(192, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (gfl_reg): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (scales): ModuleList(\n",
       "      (0): Scale()\n",
       "      (1): Scale()\n",
       "      (2): Scale()\n",
       "      (3): Scale()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from nanodet.util import cfg, load_config, load_model_weight\n",
    "from nanodet.model.arch import build_model\n",
    "\n",
    "cfg_path = \"config/nanodet-plus-m_416.yml\"\n",
    "load_config(cfg, cfg_path)\n",
    "\n",
    "model = build_model(cfg.model)\n",
    "\n",
    "ckpt = torch.load(\"data/nanodet-plus-m_416.pth\", map_location=\"cpu\")\n",
    "logger = None  # nu cn log th khi to Logger\n",
    "load_model_weight(model, ckpt, logger=None)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7962c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_visualization/model.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x = torch.randn(1, 3, 416, 416).to(device)\n",
    "y = model(x)\n",
    "\n",
    "if isinstance(y, tuple):\n",
    "    y = y[0]\n",
    "\n",
    "make_dot(y, params=dict(model.named_parameters())).render(\"model_visualization/model\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc870d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  torch.Size([1, 3, 416, 416])\n",
      "Output Shape:  torch.Size([1, 3598, 112])\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.randn(1, 3, 416, 416).to(next(model.parameters()).device)\n",
    "output = model(x)\n",
    "print(\"Input Shape: \", x.shape)\n",
    "print(\"Output Shape: \", output.shape if isinstance(output, torch.Tensor) else [o.shape for o in output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a217a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  torch.Size([1, 3, 416, 416])\n",
      "Output Shape:  torch.Size([1, 3598, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Gi s model l m hnh ca bn, v device l 'cpu' hoc 'cuda'\n",
    "x = torch.randn(1, 3, 416, 416).to(next(model.parameters()).device)\n",
    "output = model(x)\n",
    "\n",
    "# Kim tra input shape v output shape\n",
    "print(\"Input Shape: \", x.shape)\n",
    "print(\"Output Shape: \", output.shape if isinstance(output, torch.Tensor) else [o.shape for o in output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af0be53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "NanoDetPlus                                                  [1, 3598, 112]            3,132,980\n",
       "ShuffleNetV2: 1-1                                          [1, 116, 52, 52]          --\n",
       "    Sequential: 2-1                                       [1, 24, 208, 208]         --\n",
       "        Conv2d: 3-1                                      [1, 24, 208, 208]         648\n",
       "        BatchNorm2d: 3-2                                 [1, 24, 208, 208]         48\n",
       "        LeakyReLU: 3-3                                   [1, 24, 208, 208]         --\n",
       "    MaxPool2d: 2-2                                        [1, 24, 104, 104]         --\n",
       "    Sequential: 2-3                                       [1, 116, 52, 52]          --\n",
       "        ShuffleV2Block: 3-4                              [1, 116, 52, 52]          7,398\n",
       "        ShuffleV2Block: 3-5                              [1, 116, 52, 52]          7,598\n",
       "        ShuffleV2Block: 3-6                              [1, 116, 52, 52]          7,598\n",
       "        ShuffleV2Block: 3-7                              [1, 116, 52, 52]          7,598\n",
       "    Sequential: 2-4                                       [1, 232, 26, 26]          --\n",
       "        ShuffleV2Block: 3-8                              [1, 232, 26, 26]          43,616\n",
       "        ShuffleV2Block: 3-9                              [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-10                             [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-11                             [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-12                             [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-13                             [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-14                             [1, 232, 26, 26]          28,652\n",
       "        ShuffleV2Block: 3-15                             [1, 232, 26, 26]          28,652\n",
       "    Sequential: 2-5                                       [1, 464, 13, 13]          --\n",
       "        ShuffleV2Block: 3-16                             [1, 464, 13, 13]          167,968\n",
       "        ShuffleV2Block: 3-17                             [1, 464, 13, 13]          111,128\n",
       "        ShuffleV2Block: 3-18                             [1, 464, 13, 13]          111,128\n",
       "        ShuffleV2Block: 3-19                             [1, 464, 13, 13]          111,128\n",
       "GhostPAN: 1-2                                              [1, 96, 52, 52]           --\n",
       "    ModuleList: 2-6                                       --                        --\n",
       "        ConvModule: 3-20                                 [1, 96, 52, 52]           11,328\n",
       "        ConvModule: 3-21                                 [1, 96, 26, 26]           22,464\n",
       "        ConvModule: 3-22                                 [1, 96, 13, 13]           44,736\n",
       "    Upsample: 2-7                                         [1, 96, 26, 26]           --\n",
       "    ModuleList: 2-10                                      --                        (recursive)\n",
       "        GhostBlocks: 3-23                                [1, 96, 26, 26]           38,880\n",
       "    Upsample: 2-9                                         [1, 96, 52, 52]           --\n",
       "    ModuleList: 2-10                                      --                        (recursive)\n",
       "        GhostBlocks: 3-24                                [1, 96, 52, 52]           38,880\n",
       "    ModuleList: 2-13                                      --                        (recursive)\n",
       "        DepthwiseConvModule: 3-25                        [1, 96, 26, 26]           12,000\n",
       "    ModuleList: 2-14                                      --                        (recursive)\n",
       "        GhostBlocks: 3-26                                [1, 96, 26, 26]           38,880\n",
       "    ModuleList: 2-13                                      --                        (recursive)\n",
       "        DepthwiseConvModule: 3-27                        [1, 96, 13, 13]           12,000\n",
       "    ModuleList: 2-14                                      --                        (recursive)\n",
       "        GhostBlocks: 3-28                                [1, 96, 13, 13]           38,880\n",
       "    ModuleList: 2-15                                      --                        --\n",
       "        DepthwiseConvModule: 3-29                        [1, 96, 7, 7]             12,000\n",
       "    ModuleList: 2-16                                      --                        --\n",
       "        DepthwiseConvModule: 3-30                        [1, 96, 7, 7]             12,000\n",
       "NanoDetPlusHead: 1-3                                       [1, 3598, 112]            --\n",
       "    ModuleList: 2-23                                      --                        (recursive)\n",
       "        ModuleList: 3-31                                 --                        24,000\n",
       "    ModuleList: 2-24                                      --                        (recursive)\n",
       "        Conv2d: 3-32                                     [1, 112, 52, 52]          10,864\n",
       "    ModuleList: 2-23                                      --                        (recursive)\n",
       "        ModuleList: 3-33                                 --                        24,000\n",
       "    ModuleList: 2-24                                      --                        (recursive)\n",
       "        Conv2d: 3-34                                     [1, 112, 26, 26]          10,864\n",
       "    ModuleList: 2-23                                      --                        (recursive)\n",
       "        ModuleList: 3-35                                 --                        24,000\n",
       "    ModuleList: 2-24                                      --                        (recursive)\n",
       "        Conv2d: 3-36                                     [1, 112, 13, 13]          10,864\n",
       "    ModuleList: 2-23                                      --                        (recursive)\n",
       "        ModuleList: 3-37                                 --                        24,000\n",
       "    ModuleList: 2-24                                      --                        (recursive)\n",
       "        Conv2d: 3-38                                     [1, 112, 7, 7]            10,864\n",
       "==============================================================================================================\n",
       "Total params: 4,330,904\n",
       "Trainable params: 4,330,904\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 762.52\n",
       "==============================================================================================================\n",
       "Input size (MB): 2.08\n",
       "Forward/backward pass size (MB): 170.98\n",
       "Params size (MB): 4.79\n",
       "Estimated Total Size (MB): 177.84\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(1, 3, 416, 416), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ccc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # Nu out l tuple, ch ly phn t u tin hoc phn cn thit\n",
    "        if isinstance(out, tuple):\n",
    "            return out[0]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba2a240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NanoDetPlus(\n",
       "  (backbone): ShuffleNetV2(\n",
       "    (conv1): Sequential(\n",
       "      (0): QuantizedConv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), scale=0.02908726967871189, zero_point=66, padding=(1, 1), bias=False)\n",
       "      (1): QuantizedBatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (stage2): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): QuantizedConv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), scale=0.002110641449689865, zero_point=75, padding=(1, 1), groups=24, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedConv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.006850589998066425, zero_point=75, bias=False)\n",
       "          (3): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.0033291189465671778, zero_point=61, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), scale=0.0016841497272253036, zero_point=89, padding=(1, 1), groups=58, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.0038969251327216625, zero_point=67, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.0040006996132433414, zero_point=76, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), scale=0.0030461715068668127, zero_point=59, padding=(1, 1), groups=58, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.003274417482316494, zero_point=70, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.002757424023002386, zero_point=65, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), scale=0.0016400645254179835, zero_point=66, padding=(1, 1), groups=58, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.0021545642521232367, zero_point=67, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.004115924704819918, zero_point=85, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), scale=0.002797359600663185, zero_point=68, padding=(1, 1), groups=58, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), scale=0.003352543106302619, zero_point=64, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), scale=0.003493485739454627, zero_point=62, padding=(1, 1), groups=116, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.006749593652784824, zero_point=63, bias=False)\n",
       "          (3): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.004115927964448929, zero_point=68, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), scale=0.002010766416788101, zero_point=87, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.004039279650896788, zero_point=71, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.004140336532145739, zero_point=69, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.0039048970211297274, zero_point=80, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.006538104265928268, zero_point=66, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.003953383769840002, zero_point=64, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.002685328247025609, zero_point=86, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.004084458574652672, zero_point=81, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.003032584208995104, zero_point=78, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.0021586534567177296, zero_point=59, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0024896084796637297, zero_point=67, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0031026469077914953, zero_point=88, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.003386460244655609, zero_point=86, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.002733292756602168, zero_point=67, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0027730397414416075, zero_point=64, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.002240680856630206, zero_point=90, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0018713658209890127, zero_point=60, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.003208642825484276, zero_point=69, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.004431940149515867, zero_point=43, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0033849719911813736, zero_point=62, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0027461936697363853, zero_point=68, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), scale=0.0018812579801306129, zero_point=68, padding=(1, 1), groups=116, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), scale=0.0026008370332419872, zero_point=63, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): ShuffleV2Block(\n",
       "        (branch1): Sequential(\n",
       "          (0): QuantizedConv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), scale=0.0025388726498931646, zero_point=55, padding=(1, 1), groups=232, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.003607759950682521, zero_point=50, bias=False)\n",
       "          (3): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0036794214975088835, zero_point=62, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), scale=0.0015427187317982316, zero_point=28, padding=(1, 1), groups=232, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0028077492024749517, zero_point=52, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.002101478399708867, zero_point=57, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), scale=0.001485776505433023, zero_point=72, padding=(1, 1), groups=232, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0027098949067294598, zero_point=57, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0017667755018919706, zero_point=75, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), scale=0.0010759735014289618, zero_point=56, padding=(1, 1), groups=232, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0024779844097793102, zero_point=65, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ShuffleV2Block(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.0018787095323204994, zero_point=70, bias=False)\n",
       "          (1): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "          (3): QuantizedConv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), scale=0.001167935668490827, zero_point=58, padding=(1, 1), groups=232, bias=False)\n",
       "          (4): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): QuantizedConv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), scale=0.002454314613714814, zero_point=65, bias=False)\n",
       "          (6): QuantizedBatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fpn): GhostPAN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (reduce_layers): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): QuantizedConv2d(116, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.003471607342362404, zero_point=66, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): QuantizedConv2d(232, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.0028900979086756706, zero_point=72, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): QuantizedConv2d(464, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.001350046950392425, zero_point=62, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (top_down_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0014519256073981524, zero_point=76, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0007946600089780986, zero_point=70, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0013761911541223526, zero_point=58, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.00048245128709822893, zero_point=77, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.0015979314921423793, zero_point=57, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.003081131726503372, zero_point=54, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0030152732506394386, zero_point=78, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0008074459037743509, zero_point=60, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0010562987299636006, zero_point=76, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0009667867561802268, zero_point=72, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.003986561205238104, zero_point=65, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.003975096624344587, zero_point=65, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=0.021235376596450806, zero_point=30, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.0024797492660582066, zero_point=62, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=0.006147180683910847, zero_point=52, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.0024605460930615664, zero_point=75, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0030381293036043644, zero_point=63, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0006093630800023675, zero_point=48, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0021068453788757324, zero_point=62, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.001253230613656342, zero_point=59, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.005171822849661112, zero_point=54, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.0032255605328828096, zero_point=70, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0031394390389323235, zero_point=83, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0004023787914775312, zero_point=58, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.0014414229663088918, zero_point=67, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.0016641814727336168, zero_point=73, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.0021043180022388697, zero_point=57, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.003385236719623208, zero_point=67, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_in_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=0.0020718416199088097, zero_point=68, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.002965025370940566, zero_point=46, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_out_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=0.007072895299643278, zero_point=87, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.0026570186018943787, zero_point=69, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): NanoDetPlusHead(\n",
       "    (distribution_project): Integral()\n",
       "    (loss_qfl): QualityFocalLoss()\n",
       "    (loss_dfl): DistributionFocalLoss()\n",
       "    (loss_bbox): GIoULoss()\n",
       "    (cls_convs): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.01855848915874958, zero_point=35, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.003337432164698839, zero_point=78, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.009797769598662853, zero_point=43, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.007834356278181076, zero_point=70, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.009808643721044064, zero_point=54, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.00266293715685606, zero_point=67, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.008397327736020088, zero_point=39, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.006134048104286194, zero_point=56, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.00980556569993496, zero_point=45, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.002901264699175954, zero_point=73, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.00882477406412363, zero_point=72, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.005451454780995846, zero_point=66, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.002675007563084364, zero_point=68, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.00433558551594615, zero_point=61, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "        (1): DepthwiseConvModule(\n",
       "          (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), scale=0.008580640889704227, zero_point=47, padding=(2, 2), groups=96, bias=False)\n",
       "          (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.004992378409951925, zero_point=69, bias=False)\n",
       "          (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gfl_cls): ModuleList(\n",
       "      (0): QuantizedConv2d(96, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.08755858242511749, zero_point=94)\n",
       "      (1): QuantizedConv2d(96, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.08392010629177094, zero_point=104)\n",
       "      (2): QuantizedConv2d(96, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.10577429085969925, zero_point=81)\n",
       "      (3): QuantizedConv2d(96, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.14611957967281342, zero_point=90)\n",
       "    )\n",
       "  )\n",
       "  (aux_fpn): GhostPAN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (reduce_layers): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): QuantizedConv2d(116, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): QuantizedConv2d(232, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): QuantizedConv2d(464, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (bn): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (top_down_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=1.0, zero_point=0, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=1.0, zero_point=0, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): ModuleList(\n",
       "      (0): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GhostBlocks(\n",
       "        (blocks): Sequential(\n",
       "          (0): GhostBottleneck(\n",
       "            (ghost1): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (ghost2): GhostModule(\n",
       "              (primary_conv): Sequential(\n",
       "                (0): QuantizedConv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "              (cheap_operation): Sequential(\n",
       "                (0): QuantizedConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), groups=48, bias=False)\n",
       "                (1): QuantizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): Sequential()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Sequential(\n",
       "              (0): QuantizedConv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), groups=192, bias=False)\n",
       "              (1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): QuantizedConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "              (3): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_in_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=1.0, zero_point=0, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (extra_lvl_out_conv): ModuleList(\n",
       "      (0): DepthwiseConvModule(\n",
       "        (depthwise): QuantizedConv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), scale=1.0, zero_point=0, padding=(2, 2), groups=96, bias=False)\n",
       "        (pointwise): QuantizedConv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "        (dwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pwnorm): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux_head): SimpleConvHead(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (cls_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (reg_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "        (gn): QuantizedGroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "        (act): QuantizedLeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (gfl_cls): QuantizedConv2d(192, 80, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "    (gfl_reg): QuantizedConv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "    (scales): ModuleList(\n",
       "      (0): Scale()\n",
       "      (1): Scale()\n",
       "      (2): Scale()\n",
       "      (3): Scale()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.quantization\n",
    "\n",
    "# Gi s model  c load v chun b sn\n",
    "model.eval()  # Chuyn m hnh v ch  nh gi\n",
    "\n",
    "# p dng lng t ha trc khi kim tra\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "# Thc hin mt s bc inference  m hnh chun b lng t ha\n",
    "# Gi s bn c mt hm inference, bn c th s dng n  y  hun luyn m hnh\n",
    "# Trn b d liu kim th hoc mt batch bt k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d878bd50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1449 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# o thi gian trc khi chuyn i\u001b[39;00m\n\u001b[1;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime for FP32: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# o thi gian sau khi chuyn i sang INT8\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/an_workplace/ICD/obdetect_icd/nanodet/model/arch/one_stage_detector.py:41\u001b[0m, in \u001b[0;36mOneStageDetector.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfpn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     43\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/an_workplace/ICD/obdetect_icd/nanodet/model/backbone/shufflenetv2.py:177\u001b[0m, in \u001b[0;36mShuffleNetV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 177\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    179\u001b[0m     output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/ao/nn/quantized/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    460\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m    462\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/obdetect_env/lib/python3.8/site-packages/torch/_ops.py:442\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1449 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradMPS: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradXPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradHPU: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:68 [backend fallback]\nAutogradLazy: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:55 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# o thi gian trc khi chuyn i\n",
    "start_time = time.time()\n",
    "model(dummy_input)\n",
    "print(f\"Time for FP32: {time.time() - start_time:.4f} seconds\")\n",
    "\n",
    "# o thi gian sau khi chuyn i sang INT8\n",
    "start_time = time.time()\n",
    "model(dummy_input)\n",
    "print(f\"Time for INT8: {time.time() - start_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obdetect_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
