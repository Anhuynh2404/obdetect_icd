digraph {
	graph [size="323.4,323.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	127384894912688 [label="
 (1, 3598, 112)" fillcolor=darkolivegreen1]
	127384894883728 [label=PermuteBackward0]
	127384894883824 -> 127384894883728
	127384894883824 [label=CatBackward0]
	127384894883584 -> 127384894883824
	127384894883584 [label=ReshapeAliasBackward0]
	127384894884016 -> 127384894883584
	127384894884016 [label=ConvolutionBackward0]
	127384894884112 -> 127384894884016
	127384894884112 [label=LeakyReluBackward1]
	127384894884304 -> 127384894884112
	127384894884304 [label=NativeBatchNormBackward0]
	127384894884400 -> 127384894884304
	127384894884400 [label=ConvolutionBackward0]
	127384894884640 -> 127384894884400
	127384894884640 [label=LeakyReluBackward1]
	127384894884784 -> 127384894884640
	127384894884784 [label=NativeBatchNormBackward0]
	127384894884880 -> 127384894884784
	127384894884880 [label=ConvolutionBackward0]
	127384894885072 -> 127384894884880
	127384894885072 [label=LeakyReluBackward1]
	127384894885216 -> 127384894885072
	127384894885216 [label=NativeBatchNormBackward0]
	127384894884448 -> 127384894885216
	127384894884448 [label=ConvolutionBackward0]
	127384894885456 -> 127384894884448
	127384894885456 [label=LeakyReluBackward1]
	127384894885600 -> 127384894885456
	127384894885600 [label=NativeBatchNormBackward0]
	127384894885696 -> 127384894885600
	127384894885696 [label=ConvolutionBackward0]
	127384894883632 -> 127384894885696
	127384894883632 [label=AddBackward0]
	127384894984256 -> 127384894883632
	127384894984256 [label=CatBackward0]
	127384894984496 -> 127384894984256
	127384894984496 [label=NativeBatchNormBackward0]
	127384894984640 -> 127384894984496
	127384894984640 [label=ConvolutionBackward0]
	127384894984832 -> 127384894984640
	127384894984832 [label=CatBackward0]
	127384894984976 -> 127384894984832
	127384894984976 [label=LeakyReluBackward1]
	127384894985120 -> 127384894984976
	127384894985120 [label=NativeBatchNormBackward0]
	127384894985216 -> 127384894985120
	127384894985216 [label=ConvolutionBackward0]
	127384894985408 -> 127384894985216
	127384894985408 [label=CatBackward0]
	127384894985552 -> 127384894985408
	127384894985552 [label=UpsampleBilinear2DBackward1]
	127384894985696 -> 127384894985552
	127384894985696 [label=AddBackward0]
	127384894985792 -> 127384894985696
	127384894985792 [label=CatBackward0]
	127384894985936 -> 127384894985792
	127384894985936 [label=NativeBatchNormBackward0]
	127384894986080 -> 127384894985936
	127384894986080 [label=ConvolutionBackward0]
	127384894986272 -> 127384894986080
	127384894986272 [label=CatBackward0]
	127384894986416 -> 127384894986272
	127384894986416 [label=LeakyReluBackward1]
	127384894986560 -> 127384894986416
	127384894986560 [label=NativeBatchNormBackward0]
	127384894986656 -> 127384894986560
	127384894986656 [label=ConvolutionBackward0]
	127384894986848 -> 127384894986656
	127384894986848 [label=CatBackward0]
	127384894986992 -> 127384894986848
	127384894986992 [label=UpsampleBilinear2DBackward1]
	127384894987136 -> 127384894986992
	127384894987136 [label=LeakyReluBackward1]
	127384894987232 -> 127384894987136
	127384894987232 [label=NativeBatchNormBackward0]
	127384894987328 -> 127384894987232
	127384894987328 [label=ConvolutionBackward0]
	127384894987520 -> 127384894987328
	127384894987520 [label=ViewBackward0]
	127384894987664 -> 127384894987520
	127384894987664 [label=CloneBackward0]
	127384894987760 -> 127384894987664
	127384894987760 [label=TransposeBackward0]
	127384894987856 -> 127384894987760
	127384894987856 [label=ViewBackward0]
	127384894987952 -> 127384894987856
	127384894987952 [label=CatBackward0]
	127384894988048 -> 127384894987952
	127384894988048 [label=SplitBackward0]
	127384894988192 -> 127384894988048
	127384894988192 [label=ViewBackward0]
	127384894988240 -> 127384894988192
	127384894988240 [label=CloneBackward0]
	127384894996640 -> 127384894988240
	127384894996640 [label=TransposeBackward0]
	127384894996736 -> 127384894996640
	127384894996736 [label=ViewBackward0]
	127384894996832 -> 127384894996736
	127384894996832 [label=CatBackward0]
	127384894996928 -> 127384894996832
	127384894996928 [label=SplitBackward0]
	127384894997072 -> 127384894996928
	127384894997072 [label=ViewBackward0]
	127384894997168 -> 127384894997072
	127384894997168 [label=CloneBackward0]
	127384894997216 -> 127384894997168
	127384894997216 [label=TransposeBackward0]
	127384894997360 -> 127384894997216
	127384894997360 [label=ViewBackward0]
	127384894997504 -> 127384894997360
	127384894997504 [label=CatBackward0]
	127384894997648 -> 127384894997504
	127384894997648 [label=SplitBackward0]
	127384894997888 -> 127384894997648
	127384894997888 [label=ViewBackward0]
	127384894997936 -> 127384894997888
	127384894997936 [label=CloneBackward0]
	127384894998080 -> 127384894997936
	127384894998080 [label=TransposeBackward0]
	127384894998224 -> 127384894998080
	127384894998224 [label=ViewBackward0]
	127384894998368 -> 127384894998224
	127384894998368 [label=CatBackward0]
	127384894998512 -> 127384894998368
	127384894998512 [label=LeakyReluBackward1]
	127384894998752 -> 127384894998512
	127384894998752 [label=NativeBatchNormBackward0]
	127384894998800 -> 127384894998752
	127384894998800 [label=ConvolutionBackward0]
	127384894999088 -> 127384894998800
	127384894999088 [label=NativeBatchNormBackward0]
	127384894999232 -> 127384894999088
	127384894999232 [label=ConvolutionBackward0]
	127384894999424 -> 127384894999232
	127384894999424 [label=ViewBackward0]
	127384894999568 -> 127384894999424
	127384894999568 [label=CloneBackward0]
	127384894999616 -> 127384894999568
	127384894999616 [label=TransposeBackward0]
	127384894999760 -> 127384894999616
	127384894999760 [label=ViewBackward0]
	127384894999904 -> 127384894999760
	127384894999904 [label=CatBackward0]
	127384895000048 -> 127384894999904
	127384895000048 [label=SplitBackward0]
	127384895000288 -> 127384895000048
	127384895000288 [label=ViewBackward0]
	127384895000336 -> 127384895000288
	127384895000336 [label=CloneBackward0]
	127384895000480 -> 127384895000336
	127384895000480 [label=TransposeBackward0]
	127384895008880 -> 127384895000480
	127384895008880 [label=ViewBackward0]
	127384895009024 -> 127384895008880
	127384895009024 [label=CatBackward0]
	127384895009168 -> 127384895009024
	127384895009168 [label=SplitBackward0]
	127384895009408 -> 127384895009168
	127384895009408 [label=ViewBackward0]
	127384895009456 -> 127384895009408
	127384895009456 [label=CloneBackward0]
	127384895009600 -> 127384895009456
	127384895009600 [label=TransposeBackward0]
	127384895009744 -> 127384895009600
	127384895009744 [label=ViewBackward0]
	127384895009888 -> 127384895009744
	127384895009888 [label=CatBackward0]
	127384895010032 -> 127384895009888
	127384895010032 [label=SplitBackward0]
	127384895010272 -> 127384895010032
	127384895010272 [label=ViewBackward0]
	127384895010320 -> 127384895010272
	127384895010320 [label=CloneBackward0]
	127384895010464 -> 127384895010320
	127384895010464 [label=TransposeBackward0]
	127384895010608 -> 127384895010464
	127384895010608 [label=ViewBackward0]
	127384895010752 -> 127384895010608
	127384895010752 [label=CatBackward0]
	127384895010896 -> 127384895010752
	127384895010896 [label=SplitBackward0]
	127384895011136 -> 127384895010896
	127384895011136 [label=ViewBackward0]
	127384895011184 -> 127384895011136
	127384895011184 [label=CloneBackward0]
	127384895011328 -> 127384895011184
	127384895011328 [label=TransposeBackward0]
	127384895011472 -> 127384895011328
	127384895011472 [label=ViewBackward0]
	127384895011616 -> 127384895011472
	127384895011616 [label=CatBackward0]
	127384895011760 -> 127384895011616
	127384895011760 [label=SplitBackward0]
	127384895012000 -> 127384895011760
	127384895012000 [label=ViewBackward0]
	127384895012048 -> 127384895012000
	127384895012048 [label=CloneBackward0]
	127384895012192 -> 127384895012048
	127384895012192 [label=TransposeBackward0]
	127384895012336 -> 127384895012192
	127384895012336 [label=ViewBackward0]
	127384895012480 -> 127384895012336
	127384895012480 [label=CatBackward0]
	127384895012624 -> 127384895012480
	127384895012624 [label=SplitBackward0]
	127384895012816 -> 127384895012624
	127384895012816 [label=ViewBackward0]
	127384895021168 -> 127384895012816
	127384895021168 [label=CloneBackward0]
	127384895021312 -> 127384895021168
	127384895021312 [label=TransposeBackward0]
	127384895021456 -> 127384895021312
	127384895021456 [label=ViewBackward0]
	127384895021600 -> 127384895021456
	127384895021600 [label=CatBackward0]
	127384895021744 -> 127384895021600
	127384895021744 [label=SplitBackward0]
	127384895021984 -> 127384895021744
	127384895021984 [label=ViewBackward0]
	127384895022032 -> 127384895021984
	127384895022032 [label=CloneBackward0]
	127384895022176 -> 127384895022032
	127384895022176 [label=TransposeBackward0]
	127384895022320 -> 127384895022176
	127384895022320 [label=ViewBackward0]
	127384895022464 -> 127384895022320
	127384895022464 [label=CatBackward0]
	127384895022608 -> 127384895022464
	127384895022608 [label=LeakyReluBackward1]
	127384895022848 -> 127384895022608
	127384895022848 [label=NativeBatchNormBackward0]
	127384895022896 -> 127384895022848
	127384895022896 [label=ConvolutionBackward0]
	127384895023184 -> 127384895022896
	127384895023184 [label=NativeBatchNormBackward0]
	127384895023328 -> 127384895023184
	127384895023328 [label=ConvolutionBackward0]
	127384895023520 -> 127384895023328
	127384895023520 [label=ViewBackward0]
	127384895023664 -> 127384895023520
	127384895023664 [label=CloneBackward0]
	127384895023712 -> 127384895023664
	127384895023712 [label=TransposeBackward0]
	127384895023856 -> 127384895023712
	127384895023856 [label=ViewBackward0]
	127384895024000 -> 127384895023856
	127384895024000 [label=CatBackward0]
	127384895024144 -> 127384895024000
	127384895024144 [label=SplitBackward0]
	127384895024384 -> 127384895024144
	127384895024384 [label=ViewBackward0]
	127384895024432 -> 127384895024384
	127384895024432 [label=CloneBackward0]
	127384895024576 -> 127384895024432
	127384895024576 [label=TransposeBackward0]
	127384895024720 -> 127384895024576
	127384895024720 [label=ViewBackward0]
	127384895024864 -> 127384895024720
	127384895024864 [label=CatBackward0]
	127384895025008 -> 127384895024864
	127384895025008 [label=SplitBackward0]
	127384895033504 -> 127384895025008
	127384895033504 [label=ViewBackward0]
	127384895033552 -> 127384895033504
	127384895033552 [label=CloneBackward0]
	127384895033696 -> 127384895033552
	127384895033696 [label=TransposeBackward0]
	127384895033840 -> 127384895033696
	127384895033840 [label=ViewBackward0]
	127384895033984 -> 127384895033840
	127384895033984 [label=CatBackward0]
	127384895034128 -> 127384895033984
	127384895034128 [label=SplitBackward0]
	127384895034368 -> 127384895034128
	127384895034368 [label=ViewBackward0]
	127384895034416 -> 127384895034368
	127384895034416 [label=CloneBackward0]
	127384895034560 -> 127384895034416
	127384895034560 [label=TransposeBackward0]
	127384895034704 -> 127384895034560
	127384895034704 [label=ViewBackward0]
	127384895034848 -> 127384895034704
	127384895034848 [label=CatBackward0]
	127384895034992 -> 127384895034848
	127384895034992 [label=LeakyReluBackward1]
	127384895035232 -> 127384895034992
	127384895035232 [label=NativeBatchNormBackward0]
	127384895035280 -> 127384895035232
	127384895035280 [label=ConvolutionBackward0]
	127384895035568 -> 127384895035280
	127384895035568 [label=NativeBatchNormBackward0]
	127384895035712 -> 127384895035568
	127384895035712 [label=ConvolutionBackward0]
	127384895035904 -> 127384895035712
	127384895035904 [label=MaxPool2DWithIndicesBackward0]
	127384895036048 -> 127384895035904
	127384895036048 [label=LeakyReluBackward1]
	127384895036096 -> 127384895036048
	127384895036096 [label=NativeBatchNormBackward0]
	127384895036240 -> 127384895036096
	127384895036240 [label=ConvolutionBackward0]
	127384895036528 -> 127384895036240
	127384929011808 [label="backbone.conv1.0.weight
 (24, 3, 3, 3)" fillcolor=lightblue]
	127384929011808 -> 127384895036528
	127384895036528 [label=AccumulateGrad]
	127384895036192 -> 127384895036096
	127384929012128 [label="backbone.conv1.1.weight
 (24)" fillcolor=lightblue]
	127384929012128 -> 127384895036192
	127384895036192 [label=AccumulateGrad]
	127384895036336 -> 127384895036096
	127384929011888 [label="backbone.conv1.1.bias
 (24)" fillcolor=lightblue]
	127384929011888 -> 127384895036336
	127384895036336 [label=AccumulateGrad]
	127384895035856 -> 127384895035712
	127384929012288 [label="backbone.stage2.0.branch1.0.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	127384929012288 -> 127384895035856
	127384895035856 [label=AccumulateGrad]
	127384895035664 -> 127384895035568
	127384929012848 [label="backbone.stage2.0.branch1.1.weight
 (24)" fillcolor=lightblue]
	127384929012848 -> 127384895035664
	127384895035664 [label=AccumulateGrad]
	127384895035616 -> 127384895035568
	127384929012768 [label="backbone.stage2.0.branch1.1.bias
 (24)" fillcolor=lightblue]
	127384929012768 -> 127384895035616
	127384895035616 [label=AccumulateGrad]
	127384895035520 -> 127384895035280
	127384929012928 [label="backbone.stage2.0.branch1.2.weight
 (58, 24, 1, 1)" fillcolor=lightblue]
	127384929012928 -> 127384895035520
	127384895035520 [label=AccumulateGrad]
	127384895035136 -> 127384895035232
	127384929013408 [label="backbone.stage2.0.branch1.3.weight
 (58)" fillcolor=lightblue]
	127384929013408 -> 127384895035136
	127384895035136 [label=AccumulateGrad]
	127384895035376 -> 127384895035232
	127384929013328 [label="backbone.stage2.0.branch1.3.bias
 (58)" fillcolor=lightblue]
	127384929013328 -> 127384895035376
	127384895035376 [label=AccumulateGrad]
	127384895034944 -> 127384895034848
	127384895034944 [label=LeakyReluBackward1]
	127384895035472 -> 127384895034944
	127384895035472 [label=NativeBatchNormBackward0]
	127384895035808 -> 127384895035472
	127384895035808 [label=ConvolutionBackward0]
	127384895036480 -> 127384895035808
	127384895036480 [label=NativeBatchNormBackward0]
	127384895036672 -> 127384895036480
	127384895036672 [label=ConvolutionBackward0]
	127384895036960 -> 127384895036672
	127384895036960 [label=LeakyReluBackward1]
	127384895037104 -> 127384895036960
	127384895037104 [label=NativeBatchNormBackward0]
	127384895037200 -> 127384895037104
	127384895037200 [label=ConvolutionBackward0]
	127384895035904 -> 127384895037200
	127384895037392 -> 127384895037200
	127384929009808 [label="backbone.stage2.0.branch2.0.weight
 (58, 24, 1, 1)" fillcolor=lightblue]
	127384929009808 -> 127384895037392
	127384895037392 [label=AccumulateGrad]
	127384895037152 -> 127384895037104
	127384929037584 [label="backbone.stage2.0.branch2.1.weight
 (58)" fillcolor=lightblue]
	127384929037584 -> 127384895037152
	127384895037152 [label=AccumulateGrad]
	127384895037008 -> 127384895037104
	127384929034944 [label="backbone.stage2.0.branch2.1.bias
 (58)" fillcolor=lightblue]
	127384929034944 -> 127384895037008
	127384895037008 [label=AccumulateGrad]
	127384895036912 -> 127384895036672
	127384929034624 [label="backbone.stage2.0.branch2.3.weight
 (58, 1, 3, 3)" fillcolor=lightblue]
	127384929034624 -> 127384895036912
	127384895036912 [label=AccumulateGrad]
	127384895036720 -> 127384895036480
	127384929034544 [label="backbone.stage2.0.branch2.4.weight
 (58)" fillcolor=lightblue]
	127384929034544 -> 127384895036720
	127384895036720 [label=AccumulateGrad]
	127384895036768 -> 127384895036480
	127384929035104 [label="backbone.stage2.0.branch2.4.bias
 (58)" fillcolor=lightblue]
	127384929035104 -> 127384895036768
	127384895036768 [label=AccumulateGrad]
	127384895036000 -> 127384895035808
	127384929035344 [label="backbone.stage2.0.branch2.5.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384929035344 -> 127384895036000
	127384895036000 [label=AccumulateGrad]
	127384895036384 -> 127384895035472
	127384929035264 [label="backbone.stage2.0.branch2.6.weight
 (58)" fillcolor=lightblue]
	127384929035264 -> 127384895036384
	127384895036384 [label=AccumulateGrad]
	127384895035184 -> 127384895035472
	127384929035184 [label="backbone.stage2.0.branch2.6.bias
 (58)" fillcolor=lightblue]
	127384929035184 -> 127384895035184
	127384895035184 [label=AccumulateGrad]
	127384895034080 -> 127384895033984
	127384895034080 [label=LeakyReluBackward1]
	127384895034512 -> 127384895034080
	127384895034512 [label=NativeBatchNormBackward0]
	127384895034800 -> 127384895034512
	127384895034800 [label=ConvolutionBackward0]
	127384895035952 -> 127384895034800
	127384895035952 [label=NativeBatchNormBackward0]
	127384895036816 -> 127384895035952
	127384895036816 [label=ConvolutionBackward0]
	127384895037296 -> 127384895036816
	127384895037296 [label=LeakyReluBackward1]
	127384895054032 -> 127384895037296
	127384895054032 [label=NativeBatchNormBackward0]
	127384895054128 -> 127384895054032
	127384895054128 [label=ConvolutionBackward0]
	127384895034128 -> 127384895054128
	127384895054320 -> 127384895054128
	127384929035904 [label="backbone.stage2.1.branch2.0.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384929035904 -> 127384895054320
	127384895054320 [label=AccumulateGrad]
	127384895054080 -> 127384895054032
	127384929036224 [label="backbone.stage2.1.branch2.1.weight
 (58)" fillcolor=lightblue]
	127384929036224 -> 127384895054080
	127384895054080 [label=AccumulateGrad]
	127384895053936 -> 127384895054032
	127384929035824 [label="backbone.stage2.1.branch2.1.bias
 (58)" fillcolor=lightblue]
	127384929035824 -> 127384895053936
	127384895053936 [label=AccumulateGrad]
	127384895037056 -> 127384895036816
	127384929036784 [label="backbone.stage2.1.branch2.3.weight
 (58, 1, 3, 3)" fillcolor=lightblue]
	127384929036784 -> 127384895037056
	127384895037056 [label=AccumulateGrad]
	127384895036864 -> 127384895035952
	127384929036704 [label="backbone.stage2.1.branch2.4.weight
 (58)" fillcolor=lightblue]
	127384929036704 -> 127384895036864
	127384895036864 [label=AccumulateGrad]
	127384895037344 -> 127384895035952
	127384929037264 [label="backbone.stage2.1.branch2.4.bias
 (58)" fillcolor=lightblue]
	127384929037264 -> 127384895037344
	127384895037344 [label=AccumulateGrad]
	127384895035760 -> 127384895034800
	127384929036864 [label="backbone.stage2.1.branch2.5.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384929036864 -> 127384895035760
	127384895035760 [label=AccumulateGrad]
	127384895034656 -> 127384895034512
	127384929037424 [label="backbone.stage2.1.branch2.6.weight
 (58)" fillcolor=lightblue]
	127384929037424 -> 127384895034656
	127384895034656 [label=AccumulateGrad]
	127384895034320 -> 127384895034512
	127384929037344 [label="backbone.stage2.1.branch2.6.bias
 (58)" fillcolor=lightblue]
	127384929037344 -> 127384895034320
	127384895034320 [label=AccumulateGrad]
	127384895024960 -> 127384895024864
	127384895024960 [label=LeakyReluBackward1]
	127384895033648 -> 127384895024960
	127384895033648 [label=NativeBatchNormBackward0]
	127384895033936 -> 127384895033648
	127384895033936 [label=ConvolutionBackward0]
	127384895035424 -> 127384895033936
	127384895035424 [label=NativeBatchNormBackward0]
	127384895037248 -> 127384895035424
	127384895037248 [label=ConvolutionBackward0]
	127384895054368 -> 127384895037248
	127384895054368 [label=LeakyReluBackward1]
	127384895054512 -> 127384895054368
	127384895054512 [label=NativeBatchNormBackward0]
	127384895054608 -> 127384895054512
	127384895054608 [label=ConvolutionBackward0]
	127384895025008 -> 127384895054608
	127384895054800 -> 127384895054608
	127384929037904 [label="backbone.stage2.2.branch2.0.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384929037904 -> 127384895054800
	127384895054800 [label=AccumulateGrad]
	127384895054560 -> 127384895054512
	127384929037824 [label="backbone.stage2.2.branch2.1.weight
 (58)" fillcolor=lightblue]
	127384929037824 -> 127384895054560
	127384895054560 [label=AccumulateGrad]
	127384895054224 -> 127384895054512
	127384929038064 [label="backbone.stage2.2.branch2.1.bias
 (58)" fillcolor=lightblue]
	127384929038064 -> 127384895054224
	127384895054224 [label=AccumulateGrad]
	127384895054416 -> 127384895037248
	127384928649280 [label="backbone.stage2.2.branch2.3.weight
 (58, 1, 3, 3)" fillcolor=lightblue]
	127384928649280 -> 127384895054416
	127384895054416 [label=AccumulateGrad]
	127384895053888 -> 127384895035424
	127384928649360 [label="backbone.stage2.2.branch2.4.weight
 (58)" fillcolor=lightblue]
	127384928649360 -> 127384895053888
	127384895053888 [label=AccumulateGrad]
	127384895054272 -> 127384895035424
	127384928649440 [label="backbone.stage2.2.branch2.4.bias
 (58)" fillcolor=lightblue]
	127384928649440 -> 127384895054272
	127384895054272 [label=AccumulateGrad]
	127384895035088 -> 127384895033936
	127384928649840 [label="backbone.stage2.2.branch2.5.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384928649840 -> 127384895035088
	127384895035088 [label=AccumulateGrad]
	127384895033792 -> 127384895033648
	127384928649920 [label="backbone.stage2.2.branch2.6.weight
 (58)" fillcolor=lightblue]
	127384928649920 -> 127384895033792
	127384895033792 [label=AccumulateGrad]
	127384895033456 -> 127384895033648
	127384928650000 [label="backbone.stage2.2.branch2.6.bias
 (58)" fillcolor=lightblue]
	127384928650000 -> 127384895033456
	127384895033456 [label=AccumulateGrad]
	127384895024096 -> 127384895024000
	127384895024096 [label=LeakyReluBackward1]
	127384895024528 -> 127384895024096
	127384895024528 [label=NativeBatchNormBackward0]
	127384895024816 -> 127384895024528
	127384895024816 [label=ConvolutionBackward0]
	127384895034272 -> 127384895024816
	127384895034272 [label=NativeBatchNormBackward0]
	127384895054176 -> 127384895034272
	127384895054176 [label=ConvolutionBackward0]
	127384895054704 -> 127384895054176
	127384895054704 [label=LeakyReluBackward1]
	127384895055040 -> 127384895054704
	127384895055040 [label=NativeBatchNormBackward0]
	127384895055136 -> 127384895055040
	127384895055136 [label=ConvolutionBackward0]
	127384895024144 -> 127384895055136
	127384895055328 -> 127384895055136
	127384928650400 [label="backbone.stage2.3.branch2.0.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384928650400 -> 127384895055328
	127384895055328 [label=AccumulateGrad]
	127384895055088 -> 127384895055040
	127384928650480 [label="backbone.stage2.3.branch2.1.weight
 (58)" fillcolor=lightblue]
	127384928650480 -> 127384895055088
	127384895055088 [label=AccumulateGrad]
	127384895054944 -> 127384895055040
	127384928650560 [label="backbone.stage2.3.branch2.1.bias
 (58)" fillcolor=lightblue]
	127384928650560 -> 127384895054944
	127384895054944 [label=AccumulateGrad]
	127384895054848 -> 127384895054176
	127384928650960 [label="backbone.stage2.3.branch2.3.weight
 (58, 1, 3, 3)" fillcolor=lightblue]
	127384928650960 -> 127384895054848
	127384895054848 [label=AccumulateGrad]
	127384895053984 -> 127384895034272
	127384928651040 [label="backbone.stage2.3.branch2.4.weight
 (58)" fillcolor=lightblue]
	127384928651040 -> 127384895053984
	127384895053984 [label=AccumulateGrad]
	127384895054656 -> 127384895034272
	127384928651120 [label="backbone.stage2.3.branch2.4.bias
 (58)" fillcolor=lightblue]
	127384928651120 -> 127384895054656
	127384895054656 [label=AccumulateGrad]
	127384895034224 -> 127384895024816
	127384928651520 [label="backbone.stage2.3.branch2.5.weight
 (58, 58, 1, 1)" fillcolor=lightblue]
	127384928651520 -> 127384895034224
	127384895034224 [label=AccumulateGrad]
	127384895024672 -> 127384895024528
	127384928651600 [label="backbone.stage2.3.branch2.6.weight
 (58)" fillcolor=lightblue]
	127384928651600 -> 127384895024672
	127384895024672 [label=AccumulateGrad]
	127384895024336 -> 127384895024528
	127384928651680 [label="backbone.stage2.3.branch2.6.bias
 (58)" fillcolor=lightblue]
	127384928651680 -> 127384895024336
	127384895024336 [label=AccumulateGrad]
	127384895023472 -> 127384895023328
	127384928652080 [label="backbone.stage3.0.branch1.0.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928652080 -> 127384895023472
	127384895023472 [label=AccumulateGrad]
	127384895023280 -> 127384895023184
	127384928652160 [label="backbone.stage3.0.branch1.1.weight
 (116)" fillcolor=lightblue]
	127384928652160 -> 127384895023280
	127384895023280 [label=AccumulateGrad]
	127384895023232 -> 127384895023184
	127384928652240 [label="backbone.stage3.0.branch1.1.bias
 (116)" fillcolor=lightblue]
	127384928652240 -> 127384895023232
	127384895023232 [label=AccumulateGrad]
	127384895023136 -> 127384895022896
	127384928652640 [label="backbone.stage3.0.branch1.2.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928652640 -> 127384895023136
	127384895023136 [label=AccumulateGrad]
	127384895022752 -> 127384895022848
	127384928652720 [label="backbone.stage3.0.branch1.3.weight
 (116)" fillcolor=lightblue]
	127384928652720 -> 127384895022752
	127384895022752 [label=AccumulateGrad]
	127384895022992 -> 127384895022848
	127384928652800 [label="backbone.stage3.0.branch1.3.bias
 (116)" fillcolor=lightblue]
	127384928652800 -> 127384895022992
	127384895022992 [label=AccumulateGrad]
	127384895022560 -> 127384895022464
	127384895022560 [label=LeakyReluBackward1]
	127384895023088 -> 127384895022560
	127384895023088 [label=NativeBatchNormBackward0]
	127384895023424 -> 127384895023088
	127384895023424 [label=ConvolutionBackward0]
	127384895023952 -> 127384895023424
	127384895023952 [label=NativeBatchNormBackward0]
	127384895025104 -> 127384895023952
	127384895025104 [label=ConvolutionBackward0]
	127384895054464 -> 127384895025104
	127384895054464 [label=LeakyReluBackward1]
	127384895055424 -> 127384895054464
	127384895055424 [label=NativeBatchNormBackward0]
	127384895055232 -> 127384895055424
	127384895055232 [label=ConvolutionBackward0]
	127384895023520 -> 127384895055232
	127384895055616 -> 127384895055232
	127384928653200 [label="backbone.stage3.0.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928653200 -> 127384895055616
	127384895055616 [label=AccumulateGrad]
	127384895055376 -> 127384895055424
	127384928743488 [label="backbone.stage3.0.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928743488 -> 127384895055376
	127384895055376 [label=AccumulateGrad]
	127384895055184 -> 127384895055424
	127384928743568 [label="backbone.stage3.0.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928743568 -> 127384895055184
	127384895055184 [label=AccumulateGrad]
	127384895054896 -> 127384895025104
	127384928743968 [label="backbone.stage3.0.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928743968 -> 127384895054896
	127384895054896 [label=AccumulateGrad]
	127384895024288 -> 127384895023952
	127384928744048 [label="backbone.stage3.0.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928744048 -> 127384895024288
	127384895024288 [label=AccumulateGrad]
	127384895024240 -> 127384895023952
	127384928744128 [label="backbone.stage3.0.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928744128 -> 127384895024240
	127384895024240 [label=AccumulateGrad]
	127384895023616 -> 127384895023424
	127384928744528 [label="backbone.stage3.0.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928744528 -> 127384895023616
	127384895023616 [label=AccumulateGrad]
	127384895023808 -> 127384895023088
	127384928744608 [label="backbone.stage3.0.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928744608 -> 127384895023808
	127384895023808 [label=AccumulateGrad]
	127384895022800 -> 127384895023088
	127384928744688 [label="backbone.stage3.0.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928744688 -> 127384895022800
	127384895022800 [label=AccumulateGrad]
	127384895021696 -> 127384895021600
	127384895021696 [label=LeakyReluBackward1]
	127384895022128 -> 127384895021696
	127384895022128 [label=NativeBatchNormBackward0]
	127384895022416 -> 127384895022128
	127384895022416 [label=ConvolutionBackward0]
	127384895023568 -> 127384895022416
	127384895023568 [label=NativeBatchNormBackward0]
	127384895033408 -> 127384895023568
	127384895033408 [label=ConvolutionBackward0]
	127384895055664 -> 127384895033408
	127384895055664 [label=LeakyReluBackward1]
	127384895055808 -> 127384895055664
	127384895055808 [label=NativeBatchNormBackward0]
	127384895055904 -> 127384895055808
	127384895055904 [label=ConvolutionBackward0]
	127384895021744 -> 127384895055904
	127384895056096 -> 127384895055904
	127384928745088 [label="backbone.stage3.1.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928745088 -> 127384895056096
	127384895056096 [label=AccumulateGrad]
	127384895055856 -> 127384895055808
	127384928745168 [label="backbone.stage3.1.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928745168 -> 127384895055856
	127384895055856 [label=AccumulateGrad]
	127384895055520 -> 127384895055808
	127384928745248 [label="backbone.stage3.1.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928745248 -> 127384895055520
	127384895055520 [label=AccumulateGrad]
	127384895055712 -> 127384895033408
	127384928745648 [label="backbone.stage3.1.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928745648 -> 127384895055712
	127384895055712 [label=AccumulateGrad]
	127384895055280 -> 127384895023568
	127384928745728 [label="backbone.stage3.1.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928745728 -> 127384895055280
	127384895055280 [label=AccumulateGrad]
	127384895055568 -> 127384895023568
	127384928745808 [label="backbone.stage3.1.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928745808 -> 127384895055568
	127384895055568 [label=AccumulateGrad]
	127384895023376 -> 127384895022416
	127384928746208 [label="backbone.stage3.1.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928746208 -> 127384895023376
	127384895023376 [label=AccumulateGrad]
	127384895022272 -> 127384895022128
	127384928746288 [label="backbone.stage3.1.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928746288 -> 127384895022272
	127384895022272 [label=AccumulateGrad]
	127384895021936 -> 127384895022128
	127384928746368 [label="backbone.stage3.1.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928746368 -> 127384895021936
	127384895021936 [label=AccumulateGrad]
	127384895012576 -> 127384895012480
	127384895012576 [label=LeakyReluBackward1]
	127384895012768 -> 127384895012576
	127384895012768 [label=NativeBatchNormBackward0]
	127384895021552 -> 127384895012768
	127384895021552 [label=ConvolutionBackward0]
	127384895023040 -> 127384895021552
	127384895023040 [label=NativeBatchNormBackward0]
	127384895055472 -> 127384895023040
	127384895055472 [label=ConvolutionBackward0]
	127384895056144 -> 127384895055472
	127384895056144 [label=LeakyReluBackward1]
	127384895056288 -> 127384895056144
	127384895056288 [label=NativeBatchNormBackward0]
	127384895056384 -> 127384895056288
	127384895056384 [label=ConvolutionBackward0]
	127384895012624 -> 127384895056384
	127384895056576 -> 127384895056384
	127384928746768 [label="backbone.stage3.2.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928746768 -> 127384895056576
	127384895056576 [label=AccumulateGrad]
	127384895056336 -> 127384895056288
	127384928746848 [label="backbone.stage3.2.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928746848 -> 127384895056336
	127384895056336 [label=AccumulateGrad]
	127384895056000 -> 127384895056288
	127384928746928 [label="backbone.stage3.2.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928746928 -> 127384895056000
	127384895056000 [label=AccumulateGrad]
	127384895056192 -> 127384895055472
	127384928747328 [label="backbone.stage3.2.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928747328 -> 127384895056192
	127384895056192 [label=AccumulateGrad]
	127384895054992 -> 127384895023040
	127384928747408 [label="backbone.stage3.2.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928747408 -> 127384895054992
	127384895054992 [label=AccumulateGrad]
	127384895056048 -> 127384895023040
	127384928825408 [label="backbone.stage3.2.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928825408 -> 127384895056048
	127384895056048 [label=AccumulateGrad]
	127384895022704 -> 127384895021552
	127384928825808 [label="backbone.stage3.2.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928825808 -> 127384895022704
	127384895022704 [label=AccumulateGrad]
	127384895021408 -> 127384895012768
	127384928825888 [label="backbone.stage3.2.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928825888 -> 127384895021408
	127384895021408 [label=AccumulateGrad]
	127384895021120 -> 127384895012768
	127384928825968 [label="backbone.stage3.2.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928825968 -> 127384895021120
	127384895021120 [label=AccumulateGrad]
	127384895011712 -> 127384895011616
	127384895011712 [label=LeakyReluBackward1]
	127384895012144 -> 127384895011712
	127384895012144 [label=NativeBatchNormBackward0]
	127384895012432 -> 127384895012144
	127384895012432 [label=ConvolutionBackward0]
	127384895021888 -> 127384895012432
	127384895021888 [label=NativeBatchNormBackward0]
	127384895055952 -> 127384895021888
	127384895055952 [label=ConvolutionBackward0]
	127384895056624 -> 127384895055952
	127384895056624 [label=LeakyReluBackward1]
	127384895056768 -> 127384895056624
	127384895056768 [label=NativeBatchNormBackward0]
	127384895056864 -> 127384895056768
	127384895056864 [label=ConvolutionBackward0]
	127384895011760 -> 127384895056864
	127384895057056 -> 127384895056864
	127384928826368 [label="backbone.stage3.3.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928826368 -> 127384895057056
	127384895057056 [label=AccumulateGrad]
	127384895056816 -> 127384895056768
	127384928826448 [label="backbone.stage3.3.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928826448 -> 127384895056816
	127384895056816 [label=AccumulateGrad]
	127384895056480 -> 127384895056768
	127384928826528 [label="backbone.stage3.3.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928826528 -> 127384895056480
	127384895056480 [label=AccumulateGrad]
	127384895056672 -> 127384895055952
	127384928826928 [label="backbone.stage3.3.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928826928 -> 127384895056672
	127384895056672 [label=AccumulateGrad]
	127384895055760 -> 127384895021888
	127384928827008 [label="backbone.stage3.3.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928827008 -> 127384895055760
	127384895055760 [label=AccumulateGrad]
	127384895056528 -> 127384895021888
	127384928827088 [label="backbone.stage3.3.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928827088 -> 127384895056528
	127384895056528 [label=AccumulateGrad]
	127384895021840 -> 127384895012432
	127384928827488 [label="backbone.stage3.3.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928827488 -> 127384895021840
	127384895021840 [label=AccumulateGrad]
	127384895012288 -> 127384895012144
	127384928827568 [label="backbone.stage3.3.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928827568 -> 127384895012288
	127384895012288 [label=AccumulateGrad]
	127384895011952 -> 127384895012144
	127384928827648 [label="backbone.stage3.3.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928827648 -> 127384895011952
	127384895011952 [label=AccumulateGrad]
	127384895010848 -> 127384895010752
	127384895010848 [label=LeakyReluBackward1]
	127384895011280 -> 127384895010848
	127384895011280 [label=NativeBatchNormBackward0]
	127384895011568 -> 127384895011280
	127384895011568 [label=ConvolutionBackward0]
	127384895021264 -> 127384895011568
	127384895021264 [label=NativeBatchNormBackward0]
	127384895056432 -> 127384895021264
	127384895056432 [label=ConvolutionBackward0]
	127384895057104 -> 127384895056432
	127384895057104 [label=LeakyReluBackward1]
	127384895057248 -> 127384895057104
	127384895057248 [label=NativeBatchNormBackward0]
	127384895057344 -> 127384895057248
	127384895057344 [label=ConvolutionBackward0]
	127384895010896 -> 127384895057344
	127384895057536 -> 127384895057344
	127384928828048 [label="backbone.stage3.4.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928828048 -> 127384895057536
	127384895057536 [label=AccumulateGrad]
	127384895057296 -> 127384895057248
	127384928828128 [label="backbone.stage3.4.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928828128 -> 127384895057296
	127384895057296 [label=AccumulateGrad]
	127384895056960 -> 127384895057248
	127384928828208 [label="backbone.stage3.4.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928828208 -> 127384895056960
	127384895056960 [label=AccumulateGrad]
	127384895057152 -> 127384895056432
	127384928828608 [label="backbone.stage3.4.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928828608 -> 127384895057152
	127384895057152 [label=AccumulateGrad]
	127384895056240 -> 127384895021264
	127384928828688 [label="backbone.stage3.4.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928828688 -> 127384895056240
	127384895056240 [label=AccumulateGrad]
	127384895057008 -> 127384895021264
	127384928828768 [label="backbone.stage3.4.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928828768 -> 127384895057008
	127384895057008 [label=AccumulateGrad]
	127384895012720 -> 127384895011568
	127384928829168 [label="backbone.stage3.4.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928829168 -> 127384895012720
	127384895012720 [label=AccumulateGrad]
	127384895011424 -> 127384895011280
	127384928829248 [label="backbone.stage3.4.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928829248 -> 127384895011424
	127384895011424 [label=AccumulateGrad]
	127384895011088 -> 127384895011280
	127384928829328 [label="backbone.stage3.4.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928829328 -> 127384895011088
	127384895011088 [label=AccumulateGrad]
	127384895009984 -> 127384895009888
	127384895009984 [label=LeakyReluBackward1]
	127384895010416 -> 127384895009984
	127384895010416 [label=NativeBatchNormBackward0]
	127384895010704 -> 127384895010416
	127384895010704 [label=ConvolutionBackward0]
	127384895011904 -> 127384895010704
	127384895011904 [label=NativeBatchNormBackward0]
	127384895056912 -> 127384895011904
	127384895056912 [label=ConvolutionBackward0]
	127384895057584 -> 127384895056912
	127384895057584 [label=LeakyReluBackward1]
	127384895057728 -> 127384895057584
	127384895057728 [label=NativeBatchNormBackward0]
	127384895057824 -> 127384895057728
	127384895057824 [label=ConvolutionBackward0]
	127384895010032 -> 127384895057824
	127384799428768 -> 127384895057824
	127384928907648 [label="backbone.stage3.5.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928907648 -> 127384799428768
	127384799428768 [label=AccumulateGrad]
	127384895057776 -> 127384895057728
	127384928907728 [label="backbone.stage3.5.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928907728 -> 127384895057776
	127384895057776 [label=AccumulateGrad]
	127384895057440 -> 127384895057728
	127384928907808 [label="backbone.stage3.5.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928907808 -> 127384895057440
	127384895057440 [label=AccumulateGrad]
	127384895057632 -> 127384895056912
	127384928908208 [label="backbone.stage3.5.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928908208 -> 127384895057632
	127384895057632 [label=AccumulateGrad]
	127384895056720 -> 127384895011904
	127384928908288 [label="backbone.stage3.5.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928908288 -> 127384895056720
	127384895056720 [label=AccumulateGrad]
	127384895057488 -> 127384895011904
	127384928908368 [label="backbone.stage3.5.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928908368 -> 127384895057488
	127384895057488 [label=AccumulateGrad]
	127384895011856 -> 127384895010704
	127384928908768 [label="backbone.stage3.5.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928908768 -> 127384895011856
	127384895011856 [label=AccumulateGrad]
	127384895010560 -> 127384895010416
	127384928908848 [label="backbone.stage3.5.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928908848 -> 127384895010560
	127384895010560 [label=AccumulateGrad]
	127384895010224 -> 127384895010416
	127384928908928 [label="backbone.stage3.5.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928908928 -> 127384895010224
	127384895010224 [label=AccumulateGrad]
	127384895009120 -> 127384895009024
	127384895009120 [label=LeakyReluBackward1]
	127384895009552 -> 127384895009120
	127384895009552 [label=NativeBatchNormBackward0]
	127384895009840 -> 127384895009552
	127384895009840 [label=ConvolutionBackward0]
	127384895011040 -> 127384895009840
	127384895011040 [label=NativeBatchNormBackward0]
	127384895057392 -> 127384895011040
	127384895057392 [label=ConvolutionBackward0]
	127384799428816 -> 127384895057392
	127384799428816 [label=LeakyReluBackward1]
	127384799428960 -> 127384799428816
	127384799428960 [label=NativeBatchNormBackward0]
	127384799429056 -> 127384799428960
	127384799429056 [label=ConvolutionBackward0]
	127384895009168 -> 127384799429056
	127384799429248 -> 127384799429056
	127384928909408 [label="backbone.stage3.6.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928909408 -> 127384799429248
	127384799429248 [label=AccumulateGrad]
	127384799429008 -> 127384799428960
	127384928909488 [label="backbone.stage3.6.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928909488 -> 127384799429008
	127384799429008 [label=AccumulateGrad]
	127384799428672 -> 127384799428960
	127384928909568 [label="backbone.stage3.6.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928909568 -> 127384799428672
	127384799428672 [label=AccumulateGrad]
	127384799428864 -> 127384895057392
	127384928909968 [label="backbone.stage3.6.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928909968 -> 127384799428864
	127384799428864 [label=AccumulateGrad]
	127384895057200 -> 127384895011040
	127384928910048 [label="backbone.stage3.6.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928910048 -> 127384895057200
	127384895057200 [label=AccumulateGrad]
	127384895057872 -> 127384895011040
	127384928910128 [label="backbone.stage3.6.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928910128 -> 127384895057872
	127384895057872 [label=AccumulateGrad]
	127384895010992 -> 127384895009840
	127384928910528 [label="backbone.stage3.6.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928910528 -> 127384895010992
	127384895010992 [label=AccumulateGrad]
	127384895009696 -> 127384895009552
	127384928910608 [label="backbone.stage3.6.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928910608 -> 127384895009696
	127384895009696 [label=AccumulateGrad]
	127384895009360 -> 127384895009552
	127384928910688 [label="backbone.stage3.6.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928910688 -> 127384895009360
	127384895009360 [label=AccumulateGrad]
	127384895000000 -> 127384894999904
	127384895000000 [label=LeakyReluBackward1]
	127384895000432 -> 127384895000000
	127384895000432 [label=NativeBatchNormBackward0]
	127384895000240 -> 127384895000432
	127384895000240 [label=ConvolutionBackward0]
	127384895010176 -> 127384895000240
	127384895010176 [label=NativeBatchNormBackward0]
	127384895057680 -> 127384895010176
	127384895057680 [label=ConvolutionBackward0]
	127384799429296 -> 127384895057680
	127384799429296 [label=LeakyReluBackward1]
	127384799429440 -> 127384799429296
	127384799429440 [label=NativeBatchNormBackward0]
	127384799429536 -> 127384799429440
	127384799429536 [label=ConvolutionBackward0]
	127384895000048 -> 127384799429536
	127384799429728 -> 127384799429536
	127384928911088 [label="backbone.stage3.7.branch2.0.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928911088 -> 127384799429728
	127384799429728 [label=AccumulateGrad]
	127384799429488 -> 127384799429440
	127384928911168 [label="backbone.stage3.7.branch2.1.weight
 (116)" fillcolor=lightblue]
	127384928911168 -> 127384799429488
	127384799429488 [label=AccumulateGrad]
	127384799429152 -> 127384799429440
	127384928911248 [label="backbone.stage3.7.branch2.1.bias
 (116)" fillcolor=lightblue]
	127384928911248 -> 127384799429152
	127384799429152 [label=AccumulateGrad]
	127384799429344 -> 127384895057680
	127384928481664 [label="backbone.stage3.7.branch2.3.weight
 (116, 1, 3, 3)" fillcolor=lightblue]
	127384928481664 -> 127384799429344
	127384799429344 [label=AccumulateGrad]
	127384799428720 -> 127384895010176
	127384928481744 [label="backbone.stage3.7.branch2.4.weight
 (116)" fillcolor=lightblue]
	127384928481744 -> 127384799428720
	127384799428720 [label=AccumulateGrad]
	127384799429200 -> 127384895010176
	127384928481824 [label="backbone.stage3.7.branch2.4.bias
 (116)" fillcolor=lightblue]
	127384928481824 -> 127384799429200
	127384799429200 [label=AccumulateGrad]
	127384895010128 -> 127384895000240
	127384928482224 [label="backbone.stage3.7.branch2.5.weight
 (116, 116, 1, 1)" fillcolor=lightblue]
	127384928482224 -> 127384895010128
	127384895010128 [label=AccumulateGrad]
	127384895008976 -> 127384895000432
	127384928482304 [label="backbone.stage3.7.branch2.6.weight
 (116)" fillcolor=lightblue]
	127384928482304 -> 127384895008976
	127384895008976 [label=AccumulateGrad]
	127384895008832 -> 127384895000432
	127384928482384 [label="backbone.stage3.7.branch2.6.bias
 (116)" fillcolor=lightblue]
	127384928482384 -> 127384895008832
	127384895008832 [label=AccumulateGrad]
	127384894999376 -> 127384894999232
	127384928482784 [label="backbone.stage4.0.branch1.0.weight
 (232, 1, 3, 3)" fillcolor=lightblue]
	127384928482784 -> 127384894999376
	127384894999376 [label=AccumulateGrad]
	127384894999184 -> 127384894999088
	127384928482864 [label="backbone.stage4.0.branch1.1.weight
 (232)" fillcolor=lightblue]
	127384928482864 -> 127384894999184
	127384894999184 [label=AccumulateGrad]
	127384894999136 -> 127384894999088
	127384928482944 [label="backbone.stage4.0.branch1.1.bias
 (232)" fillcolor=lightblue]
	127384928482944 -> 127384894999136
	127384894999136 [label=AccumulateGrad]
	127384894999040 -> 127384894998800
	127384928483344 [label="backbone.stage4.0.branch1.2.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928483344 -> 127384894999040
	127384894999040 [label=AccumulateGrad]
	127384894998656 -> 127384894998752
	127384928483424 [label="backbone.stage4.0.branch1.3.weight
 (232)" fillcolor=lightblue]
	127384928483424 -> 127384894998656
	127384894998656 [label=AccumulateGrad]
	127384894998896 -> 127384894998752
	127384928483504 [label="backbone.stage4.0.branch1.3.bias
 (232)" fillcolor=lightblue]
	127384928483504 -> 127384894998896
	127384894998896 [label=AccumulateGrad]
	127384894998464 -> 127384894998368
	127384894998464 [label=LeakyReluBackward1]
	127384894998992 -> 127384894998464
	127384894998992 [label=NativeBatchNormBackward0]
	127384894999712 -> 127384894998992
	127384894999712 [label=ConvolutionBackward0]
	127384895000144 -> 127384894999712
	127384895000144 [label=NativeBatchNormBackward0]
	127384895009312 -> 127384895000144
	127384895009312 [label=ConvolutionBackward0]
	127384799429584 -> 127384895009312
	127384799429584 [label=LeakyReluBackward1]
	127384799429776 -> 127384799429584
	127384799429776 [label=NativeBatchNormBackward0]
	127384799429872 -> 127384799429776
	127384799429872 [label=ConvolutionBackward0]
	127384894999424 -> 127384799429872
	127384799430064 -> 127384799429872
	127384928483904 [label="backbone.stage4.0.branch2.0.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928483904 -> 127384799430064
	127384799430064 [label=AccumulateGrad]
	127384799429632 -> 127384799429776
	127384928483984 [label="backbone.stage4.0.branch2.1.weight
 (232)" fillcolor=lightblue]
	127384928483984 -> 127384799429632
	127384799429632 [label=AccumulateGrad]
	127384799429392 -> 127384799429776
	127384928484064 [label="backbone.stage4.0.branch2.1.bias
 (232)" fillcolor=lightblue]
	127384928484064 -> 127384799429392
	127384799429392 [label=AccumulateGrad]
	127384799429104 -> 127384895009312
	127384928484464 [label="backbone.stage4.0.branch2.3.weight
 (232, 1, 3, 3)" fillcolor=lightblue]
	127384928484464 -> 127384799429104
	127384799429104 [label=AccumulateGrad]
	127384895009264 -> 127384895000144
	127384928484544 [label="backbone.stage4.0.branch2.4.weight
 (232)" fillcolor=lightblue]
	127384928484544 -> 127384895009264
	127384895009264 [label=AccumulateGrad]
	127384895000192 -> 127384895000144
	127384928484624 [label="backbone.stage4.0.branch2.4.bias
 (232)" fillcolor=lightblue]
	127384928484624 -> 127384895000192
	127384895000192 [label=AccumulateGrad]
	127384894999856 -> 127384894999712
	127384928485024 [label="backbone.stage4.0.branch2.5.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928485024 -> 127384894999856
	127384894999856 [label=AccumulateGrad]
	127384894999472 -> 127384894998992
	127384928485104 [label="backbone.stage4.0.branch2.6.weight
 (232)" fillcolor=lightblue]
	127384928485104 -> 127384894999472
	127384894999472 [label=AccumulateGrad]
	127384894998704 -> 127384894998992
	127384928485184 [label="backbone.stage4.0.branch2.6.bias
 (232)" fillcolor=lightblue]
	127384928485184 -> 127384894998704
	127384894998704 [label=AccumulateGrad]
	127384894997600 -> 127384894997504
	127384894997600 [label=LeakyReluBackward1]
	127384894998032 -> 127384894997600
	127384894998032 [label=NativeBatchNormBackward0]
	127384894998320 -> 127384894998032
	127384894998320 [label=ConvolutionBackward0]
	127384894999520 -> 127384894998320
	127384894999520 [label=NativeBatchNormBackward0]
	127384799429680 -> 127384894999520
	127384799429680 [label=ConvolutionBackward0]
	127384799430112 -> 127384799429680
	127384799430112 [label=LeakyReluBackward1]
	127384799430256 -> 127384799430112
	127384799430256 [label=NativeBatchNormBackward0]
	127384799430352 -> 127384799430256
	127384799430352 [label=ConvolutionBackward0]
	127384894997648 -> 127384799430352
	127384799430544 -> 127384799430352
	127384928559328 [label="backbone.stage4.1.branch2.0.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928559328 -> 127384799430544
	127384799430544 [label=AccumulateGrad]
	127384799430304 -> 127384799430256
	127384928559408 [label="backbone.stage4.1.branch2.1.weight
 (232)" fillcolor=lightblue]
	127384928559408 -> 127384799430304
	127384799430304 [label=AccumulateGrad]
	127384799429968 -> 127384799430256
	127384928559488 [label="backbone.stage4.1.branch2.1.bias
 (232)" fillcolor=lightblue]
	127384928559488 -> 127384799429968
	127384799429968 [label=AccumulateGrad]
	127384799430160 -> 127384799429680
	127384928559888 [label="backbone.stage4.1.branch2.3.weight
 (232, 1, 3, 3)" fillcolor=lightblue]
	127384928559888 -> 127384799430160
	127384799430160 [label=AccumulateGrad]
	127384799428912 -> 127384894999520
	127384928559968 [label="backbone.stage4.1.branch2.4.weight
 (232)" fillcolor=lightblue]
	127384928559968 -> 127384799428912
	127384799428912 [label=AccumulateGrad]
	127384799430016 -> 127384894999520
	127384928560048 [label="backbone.stage4.1.branch2.4.bias
 (232)" fillcolor=lightblue]
	127384928560048 -> 127384799430016
	127384799430016 [label=AccumulateGrad]
	127384894999328 -> 127384894998320
	127384928560448 [label="backbone.stage4.1.branch2.5.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928560448 -> 127384894999328
	127384894999328 [label=AccumulateGrad]
	127384894998176 -> 127384894998032
	127384928560528 [label="backbone.stage4.1.branch2.6.weight
 (232)" fillcolor=lightblue]
	127384928560528 -> 127384894998176
	127384894998176 [label=AccumulateGrad]
	127384894997840 -> 127384894998032
	127384928560608 [label="backbone.stage4.1.branch2.6.bias
 (232)" fillcolor=lightblue]
	127384928560608 -> 127384894997840
	127384894997840 [label=AccumulateGrad]
	127384894996880 -> 127384894996832
	127384894996880 [label=LeakyReluBackward1]
	127384894996976 -> 127384894996880
	127384894996976 [label=NativeBatchNormBackward0]
	127384894997456 -> 127384894996976
	127384894997456 [label=ConvolutionBackward0]
	127384894998944 -> 127384894997456
	127384894998944 [label=NativeBatchNormBackward0]
	127384799429920 -> 127384894998944
	127384799429920 [label=ConvolutionBackward0]
	127384799430592 -> 127384799429920
	127384799430592 [label=LeakyReluBackward1]
	127384799430736 -> 127384799430592
	127384799430736 [label=NativeBatchNormBackward0]
	127384799430832 -> 127384799430736
	127384799430832 [label=ConvolutionBackward0]
	127384894996928 -> 127384799430832
	127384799431024 -> 127384799430832
	127384928561008 [label="backbone.stage4.2.branch2.0.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928561008 -> 127384799431024
	127384799431024 [label=AccumulateGrad]
	127384799430784 -> 127384799430736
	127384928561088 [label="backbone.stage4.2.branch2.1.weight
 (232)" fillcolor=lightblue]
	127384928561088 -> 127384799430784
	127384799430784 [label=AccumulateGrad]
	127384799430448 -> 127384799430736
	127384928561168 [label="backbone.stage4.2.branch2.1.bias
 (232)" fillcolor=lightblue]
	127384928561168 -> 127384799430448
	127384799430448 [label=AccumulateGrad]
	127384799430640 -> 127384799429920
	127384928561568 [label="backbone.stage4.2.branch2.3.weight
 (232, 1, 3, 3)" fillcolor=lightblue]
	127384928561568 -> 127384799430640
	127384799430640 [label=AccumulateGrad]
	127384799429824 -> 127384894998944
	127384928561648 [label="backbone.stage4.2.branch2.4.weight
 (232)" fillcolor=lightblue]
	127384928561648 -> 127384799429824
	127384799429824 [label=AccumulateGrad]
	127384799430496 -> 127384894998944
	127384928561728 [label="backbone.stage4.2.branch2.4.bias
 (232)" fillcolor=lightblue]
	127384928561728 -> 127384799430496
	127384799430496 [label=AccumulateGrad]
	127384894998608 -> 127384894997456
	127384928562128 [label="backbone.stage4.2.branch2.5.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928562128 -> 127384894998608
	127384894998608 [label=AccumulateGrad]
	127384894997312 -> 127384894996976
	127384928562208 [label="backbone.stage4.2.branch2.6.weight
 (232)" fillcolor=lightblue]
	127384928562208 -> 127384894997312
	127384894997312 [label=AccumulateGrad]
	127384894997024 -> 127384894996976
	127384928562288 [label="backbone.stage4.2.branch2.6.bias
 (232)" fillcolor=lightblue]
	127384928562288 -> 127384894997024
	127384894997024 [label=AccumulateGrad]
	127384894988000 -> 127384894987952
	127384894988000 [label=LeakyReluBackward1]
	127384894988096 -> 127384894988000
	127384894988096 [label=NativeBatchNormBackward0]
	127384894996784 -> 127384894988096
	127384894996784 [label=ConvolutionBackward0]
	127384894997792 -> 127384894996784
	127384894997792 [label=NativeBatchNormBackward0]
	127384799430400 -> 127384894997792
	127384799430400 [label=ConvolutionBackward0]
	127384799431072 -> 127384799430400
	127384799431072 [label=LeakyReluBackward1]
	127384799431216 -> 127384799431072
	127384799431216 [label=NativeBatchNormBackward0]
	127384799431312 -> 127384799431216
	127384799431312 [label=ConvolutionBackward0]
	127384894988048 -> 127384799431312
	127384799431504 -> 127384799431312
	127384928562688 [label="backbone.stage4.3.branch2.0.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384928562688 -> 127384799431504
	127384799431504 [label=AccumulateGrad]
	127384799431264 -> 127384799431216
	127384928562768 [label="backbone.stage4.3.branch2.1.weight
 (232)" fillcolor=lightblue]
	127384928562768 -> 127384799431264
	127384799431264 [label=AccumulateGrad]
	127384799430928 -> 127384799431216
	127384928562848 [label="backbone.stage4.3.branch2.1.bias
 (232)" fillcolor=lightblue]
	127384928562848 -> 127384799430928
	127384799430928 [label=AccumulateGrad]
	127384799431120 -> 127384799430400
	127384925520016 [label="backbone.stage4.3.branch2.3.weight
 (232, 1, 3, 3)" fillcolor=lightblue]
	127384925520016 -> 127384799431120
	127384799431120 [label=AccumulateGrad]
	127384799430208 -> 127384894997792
	127384925520096 [label="backbone.stage4.3.branch2.4.weight
 (232)" fillcolor=lightblue]
	127384925520096 -> 127384799430208
	127384799430208 [label=AccumulateGrad]
	127384799430976 -> 127384894997792
	127384925520176 [label="backbone.stage4.3.branch2.4.bias
 (232)" fillcolor=lightblue]
	127384925520176 -> 127384799430976
	127384799430976 [label=AccumulateGrad]
	127384894997744 -> 127384894996784
	127384925520576 [label="backbone.stage4.3.branch2.5.weight
 (232, 232, 1, 1)" fillcolor=lightblue]
	127384925520576 -> 127384894997744
	127384894997744 [label=AccumulateGrad]
	127384894996688 -> 127384894988096
	127384925520656 [label="backbone.stage4.3.branch2.6.weight
 (232)" fillcolor=lightblue]
	127384925520656 -> 127384894996688
	127384894996688 [label=AccumulateGrad]
	127384894996592 -> 127384894988096
	127384925520736 [label="backbone.stage4.3.branch2.6.bias
 (232)" fillcolor=lightblue]
	127384925520736 -> 127384894996592
	127384894996592 [label=AccumulateGrad]
	127384894987472 -> 127384894987328
	127384925362192 [label="fpn.reduce_layers.2.conv.weight
 (96, 464, 1, 1)" fillcolor=lightblue]
	127384925362192 -> 127384894987472
	127384894987472 [label=AccumulateGrad]
	127384894987280 -> 127384894987232
	127384925362512 [label="fpn.reduce_layers.2.bn.weight
 (96)" fillcolor=lightblue]
	127384925362512 -> 127384894987280
	127384894987280 [label=AccumulateGrad]
	127384894987040 -> 127384894987232
	127384925362352 [label="fpn.reduce_layers.2.bn.bias
 (96)" fillcolor=lightblue]
	127384925362352 -> 127384894987040
	127384894987040 [label=AccumulateGrad]
	127384894986944 -> 127384894986848
	127384894986944 [label=LeakyReluBackward1]
	127384894987376 -> 127384894986944
	127384894987376 [label=NativeBatchNormBackward0]
	127384894987808 -> 127384894987376
	127384894987808 [label=ConvolutionBackward0]
	127384894999424 -> 127384894987808
	127384894987568 -> 127384894987808
	127384925362992 [label="fpn.reduce_layers.1.conv.weight
 (96, 232, 1, 1)" fillcolor=lightblue]
	127384925362992 -> 127384894987568
	127384894987568 [label=AccumulateGrad]
	127384894987424 -> 127384894987376
	127384925362912 [label="fpn.reduce_layers.1.bn.weight
 (96)" fillcolor=lightblue]
	127384925362912 -> 127384894987424
	127384894987424 [label=AccumulateGrad]
	127384894987088 -> 127384894987376
	127384925362752 [label="fpn.reduce_layers.1.bn.bias
 (96)" fillcolor=lightblue]
	127384925362752 -> 127384894987088
	127384894987088 [label=AccumulateGrad]
	127384894986800 -> 127384894986656
	127384925361632 [label="fpn.top_down_blocks.0.blocks.0.ghost1.primary_conv.0.weight
 (48, 192, 1, 1)" fillcolor=lightblue]
	127384925361632 -> 127384894986800
	127384894986800 [label=AccumulateGrad]
	127384894986608 -> 127384894986560
	127384925361712 [label="fpn.top_down_blocks.0.blocks.0.ghost1.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925361712 -> 127384894986608
	127384894986608 [label=AccumulateGrad]
	127384894986464 -> 127384894986560
	127384925361472 [label="fpn.top_down_blocks.0.blocks.0.ghost1.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925361472 -> 127384894986464
	127384894986464 [label=AccumulateGrad]
	127384894986368 -> 127384894986272
	127384894986368 [label=LeakyReluBackward1]
	127384894986752 -> 127384894986368
	127384894986752 [label=NativeBatchNormBackward0]
	127384894987184 -> 127384894986752
	127384894987184 [label=ConvolutionBackward0]
	127384894986416 -> 127384894987184
	127384894987616 -> 127384894987184
	127384925361072 [label="fpn.top_down_blocks.0.blocks.0.ghost1.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925361072 -> 127384894987616
	127384894987616 [label=AccumulateGrad]
	127384894987712 -> 127384894986752
	127384925360832 [label="fpn.top_down_blocks.0.blocks.0.ghost1.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925360832 -> 127384894987712
	127384894987712 [label=AccumulateGrad]
	127384894986512 -> 127384894986752
	127384925360912 [label="fpn.top_down_blocks.0.blocks.0.ghost1.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925360912 -> 127384894986512
	127384894986512 [label=AccumulateGrad]
	127384894986224 -> 127384894986080
	127384925360272 [label="fpn.top_down_blocks.0.blocks.0.ghost2.primary_conv.0.weight
 (48, 96, 1, 1)" fillcolor=lightblue]
	127384925360272 -> 127384894986224
	127384894986224 [label=AccumulateGrad]
	127384894986032 -> 127384894985936
	127384925360432 [label="fpn.top_down_blocks.0.blocks.0.ghost2.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925360432 -> 127384894986032
	127384894986032 [label=AccumulateGrad]
	127384894985984 -> 127384894985936
	127384925339456 [label="fpn.top_down_blocks.0.blocks.0.ghost2.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925339456 -> 127384894985984
	127384894985984 [label=AccumulateGrad]
	127384894985888 -> 127384894985792
	127384894985888 [label=NativeBatchNormBackward0]
	127384894997120 -> 127384894985888
	127384894997120 [label=ConvolutionBackward0]
	127384894985936 -> 127384894997120
	127384894986896 -> 127384894997120
	127384925339216 [label="fpn.top_down_blocks.0.blocks.0.ghost2.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925339216 -> 127384894986896
	127384894986896 [label=AccumulateGrad]
	127384894996544 -> 127384894985888
	127384925338976 [label="fpn.top_down_blocks.0.blocks.0.ghost2.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925338976 -> 127384894996544
	127384894996544 [label=AccumulateGrad]
	127384894986128 -> 127384894985888
	127384925339056 [label="fpn.top_down_blocks.0.blocks.0.ghost2.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925339056 -> 127384894986128
	127384894986128 [label=AccumulateGrad]
	127384894985744 -> 127384894985696
	127384894985744 [label=NativeBatchNormBackward0]
	127384894986704 -> 127384894985744
	127384894986704 [label=ConvolutionBackward0]
	127384894986320 -> 127384894986704
	127384894986320 [label=NativeBatchNormBackward0]
	127384799431360 -> 127384894986320
	127384799431360 [label=ConvolutionBackward0]
	127384894986848 -> 127384799431360
	127384799431408 -> 127384799431360
	127384925338336 [label="fpn.top_down_blocks.0.blocks.0.shortcut.0.weight
 (192, 1, 5, 5)" fillcolor=lightblue]
	127384925338336 -> 127384799431408
	127384799431408 [label=AccumulateGrad]
	127384799430880 -> 127384894986320
	127384925338416 [label="fpn.top_down_blocks.0.blocks.0.shortcut.1.weight
 (192)" fillcolor=lightblue]
	127384925338416 -> 127384799430880
	127384799430880 [label=AccumulateGrad]
	127384799430688 -> 127384894986320
	127384925338176 [label="fpn.top_down_blocks.0.blocks.0.shortcut.1.bias
 (192)" fillcolor=lightblue]
	127384925338176 -> 127384799430688
	127384799430688 [label=AccumulateGrad]
	127384894988144 -> 127384894986704
	127384925337936 [label="fpn.top_down_blocks.0.blocks.0.shortcut.2.weight
 (96, 192, 1, 1)" fillcolor=lightblue]
	127384925337936 -> 127384894988144
	127384894988144 [label=AccumulateGrad]
	127384894986176 -> 127384894985744
	127384925337536 [label="fpn.top_down_blocks.0.blocks.0.shortcut.3.weight
 (96)" fillcolor=lightblue]
	127384925337536 -> 127384894986176
	127384894986176 [label=AccumulateGrad]
	127384894985840 -> 127384894985744
	127384925337616 [label="fpn.top_down_blocks.0.blocks.0.shortcut.3.bias
 (96)" fillcolor=lightblue]
	127384925337616 -> 127384894985840
	127384894985840 [label=AccumulateGrad]
	127384894985504 -> 127384894985408
	127384894985504 [label=LeakyReluBackward1]
	127384894987904 -> 127384894985504
	127384894987904 [label=NativeBatchNormBackward0]
	127384894985648 -> 127384894987904
	127384894985648 [label=ConvolutionBackward0]
	127384895023520 -> 127384894985648
	127384799431600 -> 127384894985648
	127384925363792 [label="fpn.reduce_layers.0.conv.weight
 (96, 116, 1, 1)" fillcolor=lightblue]
	127384925363792 -> 127384799431600
	127384799431600 [label=AccumulateGrad]
	127384799431696 -> 127384894987904
	127384925363712 [label="fpn.reduce_layers.0.bn.weight
 (96)" fillcolor=lightblue]
	127384925363712 -> 127384799431696
	127384799431696 [label=AccumulateGrad]
	127384799431456 -> 127384894987904
	127384925363552 [label="fpn.reduce_layers.0.bn.bias
 (96)" fillcolor=lightblue]
	127384925363552 -> 127384799431456
	127384799431456 [label=AccumulateGrad]
	127384894985360 -> 127384894985216
	127384925337056 [label="fpn.top_down_blocks.1.blocks.0.ghost1.primary_conv.0.weight
 (48, 192, 1, 1)" fillcolor=lightblue]
	127384925337056 -> 127384894985360
	127384894985360 [label=AccumulateGrad]
	127384894985168 -> 127384894985120
	127384925337136 [label="fpn.top_down_blocks.1.blocks.0.ghost1.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925337136 -> 127384894985168
	127384894985168 [label=AccumulateGrad]
	127384894985024 -> 127384894985120
	127384925336816 [label="fpn.top_down_blocks.1.blocks.0.ghost1.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925336816 -> 127384894985024
	127384894985024 [label=AccumulateGrad]
	127384894984928 -> 127384894984832
	127384894984928 [label=LeakyReluBackward1]
	127384894985312 -> 127384894984928
	127384894985312 [label=NativeBatchNormBackward0]
	127384894985456 -> 127384894985312
	127384894985456 [label=ConvolutionBackward0]
	127384894984976 -> 127384894985456
	127384799431744 -> 127384894985456
	127384925336496 [label="fpn.top_down_blocks.1.blocks.0.ghost1.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925336496 -> 127384799431744
	127384799431744 [label=AccumulateGrad]
	127384894985600 -> 127384894985312
	127384925336256 [label="fpn.top_down_blocks.1.blocks.0.ghost1.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925336256 -> 127384894985600
	127384894985600 [label=AccumulateGrad]
	127384894985072 -> 127384894985312
	127384925336336 [label="fpn.top_down_blocks.1.blocks.0.ghost1.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925336336 -> 127384894985072
	127384894985072 [label=AccumulateGrad]
	127384894984784 -> 127384894984640
	127384925335616 [label="fpn.top_down_blocks.1.blocks.0.ghost2.primary_conv.0.weight
 (48, 96, 1, 1)" fillcolor=lightblue]
	127384925335616 -> 127384894984784
	127384894984784 [label=AccumulateGrad]
	127384894984592 -> 127384894984496
	127384925335696 [label="fpn.top_down_blocks.1.blocks.0.ghost2.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925335696 -> 127384894984592
	127384894984592 [label=AccumulateGrad]
	127384894984544 -> 127384894984496
	127384925306688 [label="fpn.top_down_blocks.1.blocks.0.ghost2.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925306688 -> 127384894984544
	127384894984544 [label=AccumulateGrad]
	127384894984448 -> 127384894984256
	127384894984448 [label=NativeBatchNormBackward0]
	127384894985264 -> 127384894984448
	127384894985264 [label=ConvolutionBackward0]
	127384894984496 -> 127384894985264
	127384799431840 -> 127384894985264
	127384925306448 [label="fpn.top_down_blocks.1.blocks.0.ghost2.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925306448 -> 127384799431840
	127384799431840 [label=AccumulateGrad]
	127384894984736 -> 127384894984448
	127384925306128 [label="fpn.top_down_blocks.1.blocks.0.ghost2.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925306128 -> 127384894984736
	127384894984736 [label=AccumulateGrad]
	127384894984688 -> 127384894984448
	127384925306288 [label="fpn.top_down_blocks.1.blocks.0.ghost2.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925306288 -> 127384894984688
	127384894984688 [label=AccumulateGrad]
	127384894984304 -> 127384894883632
	127384894984304 [label=NativeBatchNormBackward0]
	127384894984880 -> 127384894984304
	127384894984880 [label=ConvolutionBackward0]
	127384799431888 -> 127384894984880
	127384799431888 [label=NativeBatchNormBackward0]
	127384799432032 -> 127384799431888
	127384799432032 [label=ConvolutionBackward0]
	127384894985408 -> 127384799432032
	127384799432224 -> 127384799432032
	127384925305568 [label="fpn.top_down_blocks.1.blocks.0.shortcut.0.weight
 (192, 1, 5, 5)" fillcolor=lightblue]
	127384925305568 -> 127384799432224
	127384799432224 [label=AccumulateGrad]
	127384799431984 -> 127384799431888
	127384925305648 [label="fpn.top_down_blocks.1.blocks.0.shortcut.1.weight
 (192)" fillcolor=lightblue]
	127384925305648 -> 127384799431984
	127384799431984 [label=AccumulateGrad]
	127384799431936 -> 127384799431888
	127384925305408 [label="fpn.top_down_blocks.1.blocks.0.shortcut.1.bias
 (192)" fillcolor=lightblue]
	127384925305408 -> 127384799431936
	127384799431936 [label=AccumulateGrad]
	127384799431552 -> 127384894984880
	127384925305008 [label="fpn.top_down_blocks.1.blocks.0.shortcut.2.weight
 (96, 192, 1, 1)" fillcolor=lightblue]
	127384925305008 -> 127384799431552
	127384799431552 [label=AccumulateGrad]
	127384894984400 -> 127384894984304
	127384925304768 [label="fpn.top_down_blocks.1.blocks.0.shortcut.3.weight
 (96)" fillcolor=lightblue]
	127384925304768 -> 127384894984400
	127384894984400 [label=AccumulateGrad]
	127384799431792 -> 127384894984304
	127384925304848 [label="fpn.top_down_blocks.1.blocks.0.shortcut.3.bias
 (96)" fillcolor=lightblue]
	127384925304848 -> 127384799431792
	127384799431792 [label=AccumulateGrad]
	127384894885840 -> 127384894885696
	127384925724000 [label="head.cls_convs.0.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925724000 -> 127384894885840
	127384894885840 [label=AccumulateGrad]
	127384894885648 -> 127384894885600
	127384925723840 [label="head.cls_convs.0.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925723840 -> 127384894885648
	127384894885648 [label=AccumulateGrad]
	127384894885504 -> 127384894885600
	127384925723520 [label="head.cls_convs.0.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925723520 -> 127384894885504
	127384894885504 [label=AccumulateGrad]
	127384894885408 -> 127384894884448
	127384925723760 [label="head.cls_convs.0.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925723760 -> 127384894885408
	127384894885408 [label=AccumulateGrad]
	127384894885264 -> 127384894885216
	127384925723120 [label="head.cls_convs.0.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925723120 -> 127384894885264
	127384894885264 [label=AccumulateGrad]
	127384894885120 -> 127384894885216
	127384925723200 [label="head.cls_convs.0.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925723200 -> 127384894885120
	127384894885120 [label=AccumulateGrad]
	127384894885024 -> 127384894884880
	127384925722560 [label="head.cls_convs.0.1.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925722560 -> 127384894885024
	127384894885024 [label=AccumulateGrad]
	127384894884832 -> 127384894884784
	127384925722400 [label="head.cls_convs.0.1.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925722400 -> 127384894884832
	127384894884832 [label=AccumulateGrad]
	127384894884688 -> 127384894884784
	127384925722160 [label="head.cls_convs.0.1.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925722160 -> 127384894884688
	127384894884688 [label=AccumulateGrad]
	127384894884592 -> 127384894884400
	127384925722320 [label="head.cls_convs.0.1.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925722320 -> 127384894884592
	127384894884592 [label=AccumulateGrad]
	127384894884352 -> 127384894884304
	127384925721760 [label="head.cls_convs.0.1.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925721760 -> 127384894884352
	127384894884352 [label=AccumulateGrad]
	127384894884208 -> 127384894884304
	127384925721920 [label="head.cls_convs.0.1.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925721920 -> 127384894884208
	127384894884208 [label=AccumulateGrad]
	127384894884064 -> 127384894884016
	127384925664096 [label="head.gfl_cls.0.weight
 (112, 96, 1, 1)" fillcolor=lightblue]
	127384925664096 -> 127384894884064
	127384894884064 [label=AccumulateGrad]
	127384894883920 -> 127384894884016
	127384925663776 [label="head.gfl_cls.0.bias
 (112)" fillcolor=lightblue]
	127384925663776 -> 127384894883920
	127384894883920 [label=AccumulateGrad]
	127384894883440 -> 127384894883824
	127384894883440 [label=ReshapeAliasBackward0]
	127384894884256 -> 127384894883440
	127384894884256 [label=ConvolutionBackward0]
	127384894884544 -> 127384894884256
	127384894884544 [label=LeakyReluBackward1]
	127384894885360 -> 127384894884544
	127384894885360 [label=NativeBatchNormBackward0]
	127384894885168 -> 127384894885360
	127384894885168 [label=ConvolutionBackward0]
	127384894984352 -> 127384894885168
	127384894984352 [label=LeakyReluBackward1]
	127384799432320 -> 127384894984352
	127384799432320 [label=NativeBatchNormBackward0]
	127384799432080 -> 127384799432320
	127384799432080 [label=ConvolutionBackward0]
	127384799432416 -> 127384799432080
	127384799432416 [label=LeakyReluBackward1]
	127384799432560 -> 127384799432416
	127384799432560 [label=NativeBatchNormBackward0]
	127384799432656 -> 127384799432560
	127384799432656 [label=ConvolutionBackward0]
	127384799502544 -> 127384799432656
	127384799502544 [label=LeakyReluBackward1]
	127384799502688 -> 127384799502544
	127384799502688 [label=NativeBatchNormBackward0]
	127384799502784 -> 127384799502688
	127384799502784 [label=ConvolutionBackward0]
	127384799502976 -> 127384799502784
	127384799502976 [label=AddBackward0]
	127384799503120 -> 127384799502976
	127384799503120 [label=CatBackward0]
	127384799503264 -> 127384799503120
	127384799503264 [label=NativeBatchNormBackward0]
	127384799503408 -> 127384799503264
	127384799503408 [label=ConvolutionBackward0]
	127384799503600 -> 127384799503408
	127384799503600 [label=CatBackward0]
	127384799503744 -> 127384799503600
	127384799503744 [label=LeakyReluBackward1]
	127384799503888 -> 127384799503744
	127384799503888 [label=NativeBatchNormBackward0]
	127384799503984 -> 127384799503888
	127384799503984 [label=ConvolutionBackward0]
	127384799504176 -> 127384799503984
	127384799504176 [label=CatBackward0]
	127384799504320 -> 127384799504176
	127384799504320 [label=LeakyReluBackward1]
	127384799504416 -> 127384799504320
	127384799504416 [label=NativeBatchNormBackward0]
	127384799504512 -> 127384799504416
	127384799504512 [label=ConvolutionBackward0]
	127384799504704 -> 127384799504512
	127384799504704 [label=LeakyReluBackward1]
	127384799504848 -> 127384799504704
	127384799504848 [label=NativeBatchNormBackward0]
	127384799504944 -> 127384799504848
	127384799504944 [label=ConvolutionBackward0]
	127384894883632 -> 127384799504944
	127384799505136 -> 127384799504944
	127384925304368 [label="fpn.downsamples.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925304368 -> 127384799505136
	127384799505136 [label=AccumulateGrad]
	127384799504896 -> 127384799504848
	127384925304048 [label="fpn.downsamples.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925304048 -> 127384799504896
	127384799504896 [label=AccumulateGrad]
	127384799504752 -> 127384799504848
	127384925303808 [label="fpn.downsamples.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925303808 -> 127384799504752
	127384799504752 [label=AccumulateGrad]
	127384799504656 -> 127384799504512
	127384925303968 [label="fpn.downsamples.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925303968 -> 127384799504656
	127384799504656 [label=AccumulateGrad]
	127384799504464 -> 127384799504416
	127384925303488 [label="fpn.downsamples.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925303488 -> 127384799504464
	127384799504464 [label=AccumulateGrad]
	127384799504224 -> 127384799504416
	127384925303568 [label="fpn.downsamples.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925303568 -> 127384799504224
	127384799504224 [label=AccumulateGrad]
	127384894985696 -> 127384799504176
	127384799504128 -> 127384799503984
	127384925302848 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.primary_conv.0.weight
 (48, 192, 1, 1)" fillcolor=lightblue]
	127384925302848 -> 127384799504128
	127384799504128 [label=AccumulateGrad]
	127384799503936 -> 127384799503888
	127384925274000 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925274000 -> 127384799503936
	127384799503936 [label=AccumulateGrad]
	127384799503792 -> 127384799503888
	127384925273840 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925273840 -> 127384799503792
	127384799503792 [label=AccumulateGrad]
	127384799503696 -> 127384799503600
	127384799503696 [label=LeakyReluBackward1]
	127384799504080 -> 127384799503696
	127384799504080 [label=NativeBatchNormBackward0]
	127384799504368 -> 127384799504080
	127384799504368 [label=ConvolutionBackward0]
	127384799503744 -> 127384799504368
	127384799504992 -> 127384799504368
	127384925273600 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925273600 -> 127384799504992
	127384799504992 [label=AccumulateGrad]
	127384799504560 -> 127384799504080
	127384925273200 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925273200 -> 127384799504560
	127384799504560 [label=AccumulateGrad]
	127384799503840 -> 127384799504080
	127384925273280 [label="fpn.bottom_up_blocks.0.blocks.0.ghost1.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925273280 -> 127384799503840
	127384799503840 [label=AccumulateGrad]
	127384799503552 -> 127384799503408
	127384925272720 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.primary_conv.0.weight
 (48, 96, 1, 1)" fillcolor=lightblue]
	127384925272720 -> 127384799503552
	127384799503552 [label=AccumulateGrad]
	127384799503360 -> 127384799503264
	127384925272800 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925272800 -> 127384799503360
	127384799503360 [label=AccumulateGrad]
	127384799503312 -> 127384799503264
	127384925272480 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925272480 -> 127384799503312
	127384799503312 [label=AccumulateGrad]
	127384799503216 -> 127384799503120
	127384799503216 [label=NativeBatchNormBackward0]
	127384799504272 -> 127384799503216
	127384799504272 [label=ConvolutionBackward0]
	127384799503264 -> 127384799504272
	127384799505232 -> 127384799504272
	127384925272160 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925272160 -> 127384799505232
	127384799505232 [label=AccumulateGrad]
	127384799503504 -> 127384799503216
	127384925271920 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925271920 -> 127384799503504
	127384799503504 [label=AccumulateGrad]
	127384799503456 -> 127384799503216
	127384925272000 [label="fpn.bottom_up_blocks.0.blocks.0.ghost2.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925272000 -> 127384799503456
	127384799503456 [label=AccumulateGrad]
	127384799503072 -> 127384799502976
	127384799503072 [label=NativeBatchNormBackward0]
	127384799505088 -> 127384799503072
	127384799505088 [label=ConvolutionBackward0]
	127384799505184 -> 127384799505088
	127384799505184 [label=NativeBatchNormBackward0]
	127384799505328 -> 127384799505184
	127384799505328 [label=ConvolutionBackward0]
	127384799504176 -> 127384799505328
	127384799505520 -> 127384799505328
	127384925271280 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.0.weight
 (192, 1, 5, 5)" fillcolor=lightblue]
	127384925271280 -> 127384799505520
	127384799505520 [label=AccumulateGrad]
	127384799505280 -> 127384799505184
	127384925271360 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.1.weight
 (192)" fillcolor=lightblue]
	127384925271360 -> 127384799505280
	127384799505280 [label=AccumulateGrad]
	127384799505040 -> 127384799505184
	127384925271120 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.1.bias
 (192)" fillcolor=lightblue]
	127384925271120 -> 127384799505040
	127384799505040 [label=AccumulateGrad]
	127384799503648 -> 127384799505088
	127384925270880 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.2.weight
 (96, 192, 1, 1)" fillcolor=lightblue]
	127384925270880 -> 127384799503648
	127384799503648 [label=AccumulateGrad]
	127384799504032 -> 127384799503072
	127384925270560 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.3.weight
 (96)" fillcolor=lightblue]
	127384925270560 -> 127384799504032
	127384799504032 [label=AccumulateGrad]
	127384799503168 -> 127384799503072
	127384925270720 [label="fpn.bottom_up_blocks.0.blocks.0.shortcut.3.bias
 (96)" fillcolor=lightblue]
	127384925270720 -> 127384799503168
	127384799503168 [label=AccumulateGrad]
	127384799502928 -> 127384799502784
	127384925721280 [label="head.cls_convs.1.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925721280 -> 127384799502928
	127384799502928 [label=AccumulateGrad]
	127384799502736 -> 127384799502688
	127384925721120 [label="head.cls_convs.1.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925721120 -> 127384799502736
	127384799502736 [label=AccumulateGrad]
	127384799502592 -> 127384799502688
	127384925720800 [label="head.cls_convs.1.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925720800 -> 127384799502592
	127384799502592 [label=AccumulateGrad]
	127384799502496 -> 127384799432656
	127384925721040 [label="head.cls_convs.1.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925721040 -> 127384799502496
	127384799502496 [label=AccumulateGrad]
	127384799432608 -> 127384799432560
	127384925695728 [label="head.cls_convs.1.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925695728 -> 127384799432608
	127384799432608 [label=AccumulateGrad]
	127384799432464 -> 127384799432560
	127384925695808 [label="head.cls_convs.1.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925695808 -> 127384799432464
	127384799432464 [label=AccumulateGrad]
	127384799432368 -> 127384799432080
	127384925695328 [label="head.cls_convs.1.1.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925695328 -> 127384799432368
	127384799432368 [label=AccumulateGrad]
	127384799432176 -> 127384799432320
	127384925695008 [label="head.cls_convs.1.1.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925695008 -> 127384799432176
	127384799432176 [label=AccumulateGrad]
	127384799431168 -> 127384799432320
	127384925694768 [label="head.cls_convs.1.1.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925694768 -> 127384799431168
	127384799431168 [label=AccumulateGrad]
	127384894885552 -> 127384894885168
	127384925694928 [label="head.cls_convs.1.1.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925694928 -> 127384894885552
	127384894885552 [label=AccumulateGrad]
	127384894885312 -> 127384894885360
	127384925694448 [label="head.cls_convs.1.1.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925694448 -> 127384894885312
	127384894885312 [label=AccumulateGrad]
	127384894884928 -> 127384894885360
	127384925694528 [label="head.cls_convs.1.1.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925694528 -> 127384894884928
	127384894884928 [label=AccumulateGrad]
	127384894884496 -> 127384894884256
	127384925663536 [label="head.gfl_cls.1.weight
 (112, 96, 1, 1)" fillcolor=lightblue]
	127384925663536 -> 127384894884496
	127384894884496 [label=AccumulateGrad]
	127384894883968 -> 127384894884256
	127384925663616 [label="head.gfl_cls.1.bias
 (112)" fillcolor=lightblue]
	127384925663616 -> 127384894883968
	127384894883968 [label=AccumulateGrad]
	127384894883680 -> 127384894883824
	127384894883680 [label=ReshapeAliasBackward0]
	127384894884736 -> 127384894883680
	127384894884736 [label=ConvolutionBackward0]
	127384894885744 -> 127384894884736
	127384894885744 [label=LeakyReluBackward1]
	127384799432512 -> 127384894885744
	127384799432512 [label=NativeBatchNormBackward0]
	127384799432272 -> 127384799432512
	127384799432272 [label=ConvolutionBackward0]
	127384799504800 -> 127384799432272
	127384799504800 [label=LeakyReluBackward1]
	127384799505616 -> 127384799504800
	127384799505616 [label=NativeBatchNormBackward0]
	127384799505376 -> 127384799505616
	127384799505376 [label=ConvolutionBackward0]
	127384799505712 -> 127384799505376
	127384799505712 [label=LeakyReluBackward1]
	127384799505856 -> 127384799505712
	127384799505856 [label=NativeBatchNormBackward0]
	127384799505952 -> 127384799505856
	127384799505952 [label=ConvolutionBackward0]
	127384799506144 -> 127384799505952
	127384799506144 [label=LeakyReluBackward1]
	127384799506288 -> 127384799506144
	127384799506288 [label=NativeBatchNormBackward0]
	127384799506384 -> 127384799506288
	127384799506384 [label=ConvolutionBackward0]
	127384799531216 -> 127384799506384
	127384799531216 [label=AddBackward0]
	127384799531360 -> 127384799531216
	127384799531360 [label=CatBackward0]
	127384799531504 -> 127384799531360
	127384799531504 [label=NativeBatchNormBackward0]
	127384799531648 -> 127384799531504
	127384799531648 [label=ConvolutionBackward0]
	127384799531840 -> 127384799531648
	127384799531840 [label=CatBackward0]
	127384799531984 -> 127384799531840
	127384799531984 [label=LeakyReluBackward1]
	127384799532128 -> 127384799531984
	127384799532128 [label=NativeBatchNormBackward0]
	127384799532224 -> 127384799532128
	127384799532224 [label=ConvolutionBackward0]
	127384799532416 -> 127384799532224
	127384799532416 [label=CatBackward0]
	127384799532560 -> 127384799532416
	127384799532560 [label=LeakyReluBackward1]
	127384799532656 -> 127384799532560
	127384799532656 [label=NativeBatchNormBackward0]
	127384799532752 -> 127384799532656
	127384799532752 [label=ConvolutionBackward0]
	127384799532944 -> 127384799532752
	127384799532944 [label=LeakyReluBackward1]
	127384799533088 -> 127384799532944
	127384799533088 [label=NativeBatchNormBackward0]
	127384799533184 -> 127384799533088
	127384799533184 [label=ConvolutionBackward0]
	127384799502976 -> 127384799533184
	127384799533376 -> 127384799533184
	127384925249424 [label="fpn.downsamples.1.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925249424 -> 127384799533376
	127384799533376 [label=AccumulateGrad]
	127384799533136 -> 127384799533088
	127384925249344 [label="fpn.downsamples.1.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925249344 -> 127384799533136
	127384799533136 [label=AccumulateGrad]
	127384799532992 -> 127384799533088
	127384925249024 [label="fpn.downsamples.1.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925249024 -> 127384799532992
	127384799532992 [label=AccumulateGrad]
	127384799532896 -> 127384799532752
	127384925249264 [label="fpn.downsamples.1.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925249264 -> 127384799532896
	127384799532896 [label=AccumulateGrad]
	127384799532704 -> 127384799532656
	127384925248624 [label="fpn.downsamples.1.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925248624 -> 127384799532704
	127384799532704 [label=AccumulateGrad]
	127384799532464 -> 127384799532656
	127384925248704 [label="fpn.downsamples.1.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925248704 -> 127384799532464
	127384799532464 [label=AccumulateGrad]
	127384894987136 -> 127384799532416
	127384799532368 -> 127384799532224
	127384925248064 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.primary_conv.0.weight
 (48, 192, 1, 1)" fillcolor=lightblue]
	127384925248064 -> 127384799532368
	127384799532368 [label=AccumulateGrad]
	127384799532176 -> 127384799532128
	127384925248224 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925248224 -> 127384799532176
	127384799532176 [label=AccumulateGrad]
	127384799532032 -> 127384799532128
	127384925247824 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925247824 -> 127384799532032
	127384799532032 [label=AccumulateGrad]
	127384799531936 -> 127384799531840
	127384799531936 [label=LeakyReluBackward1]
	127384799532320 -> 127384799531936
	127384799532320 [label=NativeBatchNormBackward0]
	127384799532608 -> 127384799532320
	127384799532608 [label=ConvolutionBackward0]
	127384799531984 -> 127384799532608
	127384799533232 -> 127384799532608
	127384925247584 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925247584 -> 127384799533232
	127384799533232 [label=AccumulateGrad]
	127384799532800 -> 127384799532320
	127384925247344 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925247344 -> 127384799532800
	127384799532800 [label=AccumulateGrad]
	127384799532080 -> 127384799532320
	127384925247424 [label="fpn.bottom_up_blocks.1.blocks.0.ghost1.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925247424 -> 127384799532080
	127384799532080 [label=AccumulateGrad]
	127384799531792 -> 127384799531648
	127384925246704 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.primary_conv.0.weight
 (48, 96, 1, 1)" fillcolor=lightblue]
	127384925246704 -> 127384799531792
	127384799531792 [label=AccumulateGrad]
	127384799531600 -> 127384799531504
	127384925246784 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.primary_conv.1.weight
 (48)" fillcolor=lightblue]
	127384925246784 -> 127384799531600
	127384799531600 [label=AccumulateGrad]
	127384799531552 -> 127384799531504
	127384925246544 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.primary_conv.1.bias
 (48)" fillcolor=lightblue]
	127384925246544 -> 127384799531552
	127384799531552 [label=AccumulateGrad]
	127384799531456 -> 127384799531360
	127384799531456 [label=NativeBatchNormBackward0]
	127384799532512 -> 127384799531456
	127384799532512 [label=ConvolutionBackward0]
	127384799531504 -> 127384799532512
	127384799533472 -> 127384799532512
	127384925246304 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.cheap_operation.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	127384925246304 -> 127384799533472
	127384799533472 [label=AccumulateGrad]
	127384799531744 -> 127384799531456
	127384925245904 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.cheap_operation.1.weight
 (48)" fillcolor=lightblue]
	127384925245904 -> 127384799531744
	127384799531744 [label=AccumulateGrad]
	127384799531696 -> 127384799531456
	127384925245984 [label="fpn.bottom_up_blocks.1.blocks.0.ghost2.cheap_operation.1.bias
 (48)" fillcolor=lightblue]
	127384925245984 -> 127384799531696
	127384799531696 [label=AccumulateGrad]
	127384799531312 -> 127384799531216
	127384799531312 [label=NativeBatchNormBackward0]
	127384799533328 -> 127384799531312
	127384799533328 [label=ConvolutionBackward0]
	127384799533424 -> 127384799533328
	127384799533424 [label=NativeBatchNormBackward0]
	127384799533568 -> 127384799533424
	127384799533568 [label=ConvolutionBackward0]
	127384799532416 -> 127384799533568
	127384799533760 -> 127384799533568
	127384925245504 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.0.weight
 (192, 1, 5, 5)" fillcolor=lightblue]
	127384925245504 -> 127384799533760
	127384799533760 [label=AccumulateGrad]
	127384799533520 -> 127384799533424
	127384925753232 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.1.weight
 (192)" fillcolor=lightblue]
	127384925753232 -> 127384799533520
	127384799533520 [label=AccumulateGrad]
	127384799533280 -> 127384799533424
	127384925752992 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.1.bias
 (192)" fillcolor=lightblue]
	127384925752992 -> 127384799533280
	127384799533280 [label=AccumulateGrad]
	127384799531888 -> 127384799533328
	127384925752672 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.2.weight
 (96, 192, 1, 1)" fillcolor=lightblue]
	127384925752672 -> 127384799531888
	127384799531888 [label=AccumulateGrad]
	127384799532272 -> 127384799531312
	127384925752432 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.3.weight
 (96)" fillcolor=lightblue]
	127384925752432 -> 127384799532272
	127384799532272 [label=AccumulateGrad]
	127384799531408 -> 127384799531312
	127384925752512 [label="fpn.bottom_up_blocks.1.blocks.0.shortcut.3.bias
 (96)" fillcolor=lightblue]
	127384925752512 -> 127384799531408
	127384799531408 [label=AccumulateGrad]
	127384799531168 -> 127384799506384
	127384925693888 [label="head.cls_convs.2.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925693888 -> 127384799531168
	127384799531168 [label=AccumulateGrad]
	127384799506336 -> 127384799506288
	127384925693728 [label="head.cls_convs.2.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925693728 -> 127384799506336
	127384799506336 [label=AccumulateGrad]
	127384799506192 -> 127384799506288
	127384925693488 [label="head.cls_convs.2.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925693488 -> 127384799506192
	127384799506192 [label=AccumulateGrad]
	127384799506096 -> 127384799505952
	127384925693648 [label="head.cls_convs.2.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925693648 -> 127384799506096
	127384799506096 [label=AccumulateGrad]
	127384799505904 -> 127384799505856
	127384925693008 [label="head.cls_convs.2.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925693008 -> 127384799505904
	127384799505904 [label=AccumulateGrad]
	127384799505760 -> 127384799505856
	127384925693088 [label="head.cls_convs.2.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925693088 -> 127384799505760
	127384799505760 [label=AccumulateGrad]
	127384799505664 -> 127384799505376
	127384925692608 [label="head.cls_convs.2.1.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925692608 -> 127384799505664
	127384799505664 [label=AccumulateGrad]
	127384799505472 -> 127384799505616
	127384925692448 [label="head.cls_convs.2.1.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925692448 -> 127384799505472
	127384799505472 [label=AccumulateGrad]
	127384799504608 -> 127384799505616
	127384925692048 [label="head.cls_convs.2.1.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925692048 -> 127384799504608
	127384799504608 [label=AccumulateGrad]
	127384799502640 -> 127384799432272
	127384925692288 [label="head.cls_convs.2.1.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925692288 -> 127384799502640
	127384799502640 [label=AccumulateGrad]
	127384799502400 -> 127384799432512
	127384925667056 [label="head.cls_convs.2.1.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925667056 -> 127384799502400
	127384799502400 [label=AccumulateGrad]
	127384799502448 -> 127384799432512
	127384925667136 [label="head.cls_convs.2.1.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925667136 -> 127384799502448
	127384799502448 [label=AccumulateGrad]
	127384894885792 -> 127384894884736
	127384925663456 [label="head.gfl_cls.2.weight
 (112, 96, 1, 1)" fillcolor=lightblue]
	127384925663456 -> 127384894885792
	127384894885792 [label=AccumulateGrad]
	127384894884160 -> 127384894884736
	127384925663296 [label="head.gfl_cls.2.bias
 (112)" fillcolor=lightblue]
	127384925663296 -> 127384894884160
	127384894884160 [label=AccumulateGrad]
	127384894883488 -> 127384894883824
	127384894883488 [label=ReshapeAliasBackward0]
	127384799431648 -> 127384894883488
	127384799431648 [label=ConvolutionBackward0]
	127384894884976 -> 127384799431648
	127384894884976 [label=LeakyReluBackward1]
	127384799506048 -> 127384894884976
	127384799506048 [label=NativeBatchNormBackward0]
	127384799505808 -> 127384799506048
	127384799505808 [label=ConvolutionBackward0]
	127384799533040 -> 127384799505808
	127384799533040 [label=LeakyReluBackward1]
	127384799533856 -> 127384799533040
	127384799533856 [label=NativeBatchNormBackward0]
	127384799533616 -> 127384799533856
	127384799533616 [label=ConvolutionBackward0]
	127384799533952 -> 127384799533616
	127384799533952 [label=LeakyReluBackward1]
	127384799534096 -> 127384799533952
	127384799534096 [label=NativeBatchNormBackward0]
	127384799534192 -> 127384799534096
	127384799534192 [label=ConvolutionBackward0]
	127384799534384 -> 127384799534192
	127384799534384 [label=LeakyReluBackward1]
	127384799534528 -> 127384799534384
	127384799534528 [label=NativeBatchNormBackward0]
	127384799534624 -> 127384799534528
	127384799534624 [label=ConvolutionBackward0]
	127384799534816 -> 127384799534624
	127384799534816 [label=AddBackward0]
	127384799534960 -> 127384799534816
	127384799534960 [label=LeakyReluBackward1]
	127384799535056 -> 127384799534960
	127384799535056 [label=NativeBatchNormBackward0]
	127384799563936 -> 127384799535056
	127384799563936 [label=ConvolutionBackward0]
	127384799564128 -> 127384799563936
	127384799564128 [label=LeakyReluBackward1]
	127384799564272 -> 127384799564128
	127384799564272 [label=NativeBatchNormBackward0]
	127384799564368 -> 127384799564272
	127384799564368 [label=ConvolutionBackward0]
	127384894987136 -> 127384799564368
	127384799564560 -> 127384799564368
	127384925751872 [label="fpn.extra_lvl_in_conv.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925751872 -> 127384799564560
	127384799564560 [label=AccumulateGrad]
	127384799564320 -> 127384799564272
	127384925751712 [label="fpn.extra_lvl_in_conv.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925751712 -> 127384799564320
	127384799564320 [label=AccumulateGrad]
	127384799564176 -> 127384799564272
	127384925751472 [label="fpn.extra_lvl_in_conv.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925751472 -> 127384799564176
	127384799564176 [label=AccumulateGrad]
	127384799564080 -> 127384799563936
	127384925751632 [label="fpn.extra_lvl_in_conv.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925751632 -> 127384799564080
	127384799564080 [label=AccumulateGrad]
	127384799563888 -> 127384799535056
	127384925751072 [label="fpn.extra_lvl_in_conv.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925751072 -> 127384799563888
	127384799563888 [label=AccumulateGrad]
	127384799563840 -> 127384799535056
	127384925751232 [label="fpn.extra_lvl_in_conv.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925751232 -> 127384799563840
	127384799563840 [label=AccumulateGrad]
	127384799534912 -> 127384799534816
	127384799534912 [label=LeakyReluBackward1]
	127384799535008 -> 127384799534912
	127384799535008 [label=NativeBatchNormBackward0]
	127384799564416 -> 127384799535008
	127384799564416 [label=ConvolutionBackward0]
	127384799564464 -> 127384799564416
	127384799564464 [label=LeakyReluBackward1]
	127384799564800 -> 127384799564464
	127384799564800 [label=NativeBatchNormBackward0]
	127384799564896 -> 127384799564800
	127384799564896 [label=ConvolutionBackward0]
	127384799531216 -> 127384799564896
	127384799565088 -> 127384799564896
	127384925750592 [label="fpn.extra_lvl_out_conv.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925750592 -> 127384799565088
	127384799565088 [label=AccumulateGrad]
	127384799564848 -> 127384799564800
	127384925750432 [label="fpn.extra_lvl_out_conv.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925750432 -> 127384799564848
	127384799564848 [label=AccumulateGrad]
	127384799564704 -> 127384799564800
	127384925750112 [label="fpn.extra_lvl_out_conv.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925750112 -> 127384799564704
	127384799564704 [label=AccumulateGrad]
	127384799564608 -> 127384799564416
	127384925750352 [label="fpn.extra_lvl_out_conv.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925750352 -> 127384799564608
	127384799564608 [label=AccumulateGrad]
	127384799564512 -> 127384799535008
	127384925749712 [label="fpn.extra_lvl_out_conv.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925749712 -> 127384799564512
	127384799564512 [label=AccumulateGrad]
	127384799563984 -> 127384799535008
	127384925749792 [label="fpn.extra_lvl_out_conv.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925749792 -> 127384799563984
	127384799563984 [label=AccumulateGrad]
	127384799534768 -> 127384799534624
	127384925666496 [label="head.cls_convs.3.0.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925666496 -> 127384799534768
	127384799534768 [label=AccumulateGrad]
	127384799534576 -> 127384799534528
	127384925666336 [label="head.cls_convs.3.0.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925666336 -> 127384799534576
	127384799534576 [label=AccumulateGrad]
	127384799534432 -> 127384799534528
	127384925666096 [label="head.cls_convs.3.0.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925666096 -> 127384799534432
	127384799534432 [label=AccumulateGrad]
	127384799534336 -> 127384799534192
	127384925666256 [label="head.cls_convs.3.0.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925666256 -> 127384799534336
	127384799534336 [label=AccumulateGrad]
	127384799534144 -> 127384799534096
	127384925665696 [label="head.cls_convs.3.0.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925665696 -> 127384799534144
	127384799534144 [label=AccumulateGrad]
	127384799534000 -> 127384799534096
	127384925665856 [label="head.cls_convs.3.0.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925665856 -> 127384799534000
	127384799534000 [label=AccumulateGrad]
	127384799533904 -> 127384799533616
	127384925665216 [label="head.cls_convs.3.1.depthwise.weight
 (96, 1, 5, 5)" fillcolor=lightblue]
	127384925665216 -> 127384799533904
	127384799533904 [label=AccumulateGrad]
	127384799533712 -> 127384799533856
	127384925665056 [label="head.cls_convs.3.1.dwnorm.weight
 (96)" fillcolor=lightblue]
	127384925665056 -> 127384799533712
	127384799533712 [label=AccumulateGrad]
	127384799532848 -> 127384799533856
	127384925664736 [label="head.cls_convs.3.1.dwnorm.bias
 (96)" fillcolor=lightblue]
	127384925664736 -> 127384799532848
	127384799532848 [label=AccumulateGrad]
	127384799531072 -> 127384799505808
	127384925664976 [label="head.cls_convs.3.1.pointwise.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	127384925664976 -> 127384799531072
	127384799531072 [label=AccumulateGrad]
	127384799506000 -> 127384799506048
	127384925664336 [label="head.cls_convs.3.1.pwnorm.weight
 (96)" fillcolor=lightblue]
	127384925664336 -> 127384799506000
	127384799506000 [label=AccumulateGrad]
	127384799505568 -> 127384799506048
	127384925664416 [label="head.cls_convs.3.1.pwnorm.bias
 (96)" fillcolor=lightblue]
	127384925664416 -> 127384799505568
	127384799505568 [label=AccumulateGrad]
	127384799502832 -> 127384799431648
	127384925642480 [label="head.gfl_cls.3.weight
 (112, 96, 1, 1)" fillcolor=lightblue]
	127384925642480 -> 127384799502832
	127384799502832 [label=AccumulateGrad]
	127384799502880 -> 127384799431648
	127384925642560 [label="head.gfl_cls.3.bias
 (112)" fillcolor=lightblue]
	127384925642560 -> 127384799502880
	127384799502880 [label=AccumulateGrad]
	127384894883728 -> 127384894912688
	127384894912288 [label="
 (1, 112, 3598)" fillcolor=darkolivegreen3]
	127384894883824 -> 127384894912288
	127384894912288 -> 127384894912688 [style=dotted]
}
